#if 0
#elif defined(__arm64__) && __arm64__
// Generated by Apple Swift version 5.7 (swiftlang-5.7.0.127.4 clang-1400.0.29.50)
#ifndef AMAZONCHIMESDK_SWIFT_H
#define AMAZONCHIMESDK_SWIFT_H
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wgcc-compat"

#if !defined(__has_include)
# define __has_include(x) 0
#endif
#if !defined(__has_attribute)
# define __has_attribute(x) 0
#endif
#if !defined(__has_feature)
# define __has_feature(x) 0
#endif
#if !defined(__has_warning)
# define __has_warning(x) 0
#endif

#if __has_include(<swift/objc-prologue.h>)
# include <swift/objc-prologue.h>
#endif

#pragma clang diagnostic ignored "-Wduplicate-method-match"
#pragma clang diagnostic ignored "-Wauto-import"
#if defined(__OBJC__)
#include <Foundation/Foundation.h>
#endif
#if defined(__cplusplus)
#include <cstdint>
#include <cstddef>
#include <cstdbool>
#else
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#endif

#if !defined(SWIFT_TYPEDEFS)
# define SWIFT_TYPEDEFS 1
# if __has_include(<uchar.h>)
#  include <uchar.h>
# elif !defined(__cplusplus)
typedef uint_least16_t char16_t;
typedef uint_least32_t char32_t;
# endif
typedef float swift_float2  __attribute__((__ext_vector_type__(2)));
typedef float swift_float3  __attribute__((__ext_vector_type__(3)));
typedef float swift_float4  __attribute__((__ext_vector_type__(4)));
typedef double swift_double2  __attribute__((__ext_vector_type__(2)));
typedef double swift_double3  __attribute__((__ext_vector_type__(3)));
typedef double swift_double4  __attribute__((__ext_vector_type__(4)));
typedef int swift_int2  __attribute__((__ext_vector_type__(2)));
typedef int swift_int3  __attribute__((__ext_vector_type__(3)));
typedef int swift_int4  __attribute__((__ext_vector_type__(4)));
typedef unsigned int swift_uint2  __attribute__((__ext_vector_type__(2)));
typedef unsigned int swift_uint3  __attribute__((__ext_vector_type__(3)));
typedef unsigned int swift_uint4  __attribute__((__ext_vector_type__(4)));
#endif

#if !defined(SWIFT_PASTE)
# define SWIFT_PASTE_HELPER(x, y) x##y
# define SWIFT_PASTE(x, y) SWIFT_PASTE_HELPER(x, y)
#endif
#if !defined(SWIFT_METATYPE)
# define SWIFT_METATYPE(X) Class
#endif
#if !defined(SWIFT_CLASS_PROPERTY)
# if __has_feature(objc_class_property)
#  define SWIFT_CLASS_PROPERTY(...) __VA_ARGS__
# else
#  define SWIFT_CLASS_PROPERTY(...)
# endif
#endif

#if __has_attribute(objc_runtime_name)
# define SWIFT_RUNTIME_NAME(X) __attribute__((objc_runtime_name(X)))
#else
# define SWIFT_RUNTIME_NAME(X)
#endif
#if __has_attribute(swift_name)
# define SWIFT_COMPILE_NAME(X) __attribute__((swift_name(X)))
#else
# define SWIFT_COMPILE_NAME(X)
#endif
#if __has_attribute(objc_method_family)
# define SWIFT_METHOD_FAMILY(X) __attribute__((objc_method_family(X)))
#else
# define SWIFT_METHOD_FAMILY(X)
#endif
#if __has_attribute(noescape)
# define SWIFT_NOESCAPE __attribute__((noescape))
#else
# define SWIFT_NOESCAPE
#endif
#if __has_attribute(ns_consumed)
# define SWIFT_RELEASES_ARGUMENT __attribute__((ns_consumed))
#else
# define SWIFT_RELEASES_ARGUMENT
#endif
#if __has_attribute(warn_unused_result)
# define SWIFT_WARN_UNUSED_RESULT __attribute__((warn_unused_result))
#else
# define SWIFT_WARN_UNUSED_RESULT
#endif
#if __has_attribute(noreturn)
# define SWIFT_NORETURN __attribute__((noreturn))
#else
# define SWIFT_NORETURN
#endif
#if !defined(SWIFT_CLASS_EXTRA)
# define SWIFT_CLASS_EXTRA
#endif
#if !defined(SWIFT_PROTOCOL_EXTRA)
# define SWIFT_PROTOCOL_EXTRA
#endif
#if !defined(SWIFT_ENUM_EXTRA)
# define SWIFT_ENUM_EXTRA
#endif
#if !defined(SWIFT_CLASS)
# if __has_attribute(objc_subclassing_restricted)
#  define SWIFT_CLASS(SWIFT_NAME) SWIFT_RUNTIME_NAME(SWIFT_NAME) __attribute__((objc_subclassing_restricted)) SWIFT_CLASS_EXTRA
#  define SWIFT_CLASS_NAMED(SWIFT_NAME) __attribute__((objc_subclassing_restricted)) SWIFT_COMPILE_NAME(SWIFT_NAME) SWIFT_CLASS_EXTRA
# else
#  define SWIFT_CLASS(SWIFT_NAME) SWIFT_RUNTIME_NAME(SWIFT_NAME) SWIFT_CLASS_EXTRA
#  define SWIFT_CLASS_NAMED(SWIFT_NAME) SWIFT_COMPILE_NAME(SWIFT_NAME) SWIFT_CLASS_EXTRA
# endif
#endif
#if !defined(SWIFT_RESILIENT_CLASS)
# if __has_attribute(objc_class_stub)
#  define SWIFT_RESILIENT_CLASS(SWIFT_NAME) SWIFT_CLASS(SWIFT_NAME) __attribute__((objc_class_stub))
#  define SWIFT_RESILIENT_CLASS_NAMED(SWIFT_NAME) __attribute__((objc_class_stub)) SWIFT_CLASS_NAMED(SWIFT_NAME)
# else
#  define SWIFT_RESILIENT_CLASS(SWIFT_NAME) SWIFT_CLASS(SWIFT_NAME)
#  define SWIFT_RESILIENT_CLASS_NAMED(SWIFT_NAME) SWIFT_CLASS_NAMED(SWIFT_NAME)
# endif
#endif

#if !defined(SWIFT_PROTOCOL)
# define SWIFT_PROTOCOL(SWIFT_NAME) SWIFT_RUNTIME_NAME(SWIFT_NAME) SWIFT_PROTOCOL_EXTRA
# define SWIFT_PROTOCOL_NAMED(SWIFT_NAME) SWIFT_COMPILE_NAME(SWIFT_NAME) SWIFT_PROTOCOL_EXTRA
#endif

#if !defined(SWIFT_EXTENSION)
# define SWIFT_EXTENSION(M) SWIFT_PASTE(M##_Swift_, __LINE__)
#endif

#if !defined(OBJC_DESIGNATED_INITIALIZER)
# if __has_attribute(objc_designated_initializer)
#  define OBJC_DESIGNATED_INITIALIZER __attribute__((objc_designated_initializer))
# else
#  define OBJC_DESIGNATED_INITIALIZER
# endif
#endif
#if !defined(SWIFT_ENUM_ATTR)
# if defined(__has_attribute) && __has_attribute(enum_extensibility)
#  define SWIFT_ENUM_ATTR(_extensibility) __attribute__((enum_extensibility(_extensibility)))
# else
#  define SWIFT_ENUM_ATTR(_extensibility)
# endif
#endif
#if !defined(SWIFT_ENUM)
# define SWIFT_ENUM(_type, _name, _extensibility) enum _name : _type _name; enum SWIFT_ENUM_ATTR(_extensibility) SWIFT_ENUM_EXTRA _name : _type
# if __has_feature(generalized_swift_name)
#  define SWIFT_ENUM_NAMED(_type, _name, SWIFT_NAME, _extensibility) enum _name : _type _name SWIFT_COMPILE_NAME(SWIFT_NAME); enum SWIFT_COMPILE_NAME(SWIFT_NAME) SWIFT_ENUM_ATTR(_extensibility) SWIFT_ENUM_EXTRA _name : _type
# else
#  define SWIFT_ENUM_NAMED(_type, _name, SWIFT_NAME, _extensibility) SWIFT_ENUM(_type, _name, _extensibility)
# endif
#endif
#if !defined(SWIFT_UNAVAILABLE)
# define SWIFT_UNAVAILABLE __attribute__((unavailable))
#endif
#if !defined(SWIFT_UNAVAILABLE_MSG)
# define SWIFT_UNAVAILABLE_MSG(msg) __attribute__((unavailable(msg)))
#endif
#if !defined(SWIFT_AVAILABILITY)
# define SWIFT_AVAILABILITY(plat, ...) __attribute__((availability(plat, __VA_ARGS__)))
#endif
#if !defined(SWIFT_WEAK_IMPORT)
# define SWIFT_WEAK_IMPORT __attribute__((weak_import))
#endif
#if !defined(SWIFT_DEPRECATED)
# define SWIFT_DEPRECATED __attribute__((deprecated))
#endif
#if !defined(SWIFT_DEPRECATED_MSG)
# define SWIFT_DEPRECATED_MSG(...) __attribute__((deprecated(__VA_ARGS__)))
#endif
#if __has_feature(attribute_diagnose_if_objc)
# define SWIFT_DEPRECATED_OBJC(Msg) __attribute__((diagnose_if(1, Msg, "warning")))
#else
# define SWIFT_DEPRECATED_OBJC(Msg) SWIFT_DEPRECATED_MSG(Msg)
#endif
#if defined(__OBJC__)
#if !defined(IBSegueAction)
# define IBSegueAction
#endif
#endif
#if !defined(SWIFT_EXTERN)
# if defined(__cplusplus)
#  define SWIFT_EXTERN extern "C"
# else
#  define SWIFT_EXTERN extern
# endif
#endif
#if !defined(SWIFT_CALL)
# define SWIFT_CALL __attribute__((swiftcall))
#endif
#if defined(__cplusplus)
#if !defined(SWIFT_NOEXCEPT)
# define SWIFT_NOEXCEPT noexcept
#endif
#else
#if !defined(SWIFT_NOEXCEPT)
# define SWIFT_NOEXCEPT 
#endif
#endif
#if defined(__cplusplus)
#if !defined(SWIFT_CXX_INT_DEFINED)
#define SWIFT_CXX_INT_DEFINED
namespace swift {
using Int = ptrdiff_t;
using UInt = size_t;
}
#endif
#endif
#if defined(__OBJC__)
#if __has_feature(modules)
#if __has_warning("-Watimport-in-framework-header")
#pragma clang diagnostic ignored "-Watimport-in-framework-header"
#endif
@import AVFAudio;
@import AVFoundation;
@import AmazonChimeSDKMedia;
@import CoreFoundation;
@import CoreMedia;
@import CoreVideo;
@import Foundation;
@import ObjectiveC;
@import UIKit;
#endif

#endif
#pragma clang diagnostic ignored "-Wproperty-attribute-mismatch"
#pragma clang diagnostic ignored "-Wduplicate-method-arg"
#if __has_warning("-Wpragma-clang-attribute")
# pragma clang diagnostic ignored "-Wpragma-clang-attribute"
#endif
#pragma clang diagnostic ignored "-Wunknown-pragmas"
#pragma clang diagnostic ignored "-Wnullability"
#pragma clang diagnostic ignored "-Wdollar-in-identifier-extension"

#if __has_attribute(external_source_symbol)
# pragma push_macro("any")
# undef any
# pragma clang attribute push(__attribute__((external_source_symbol(language="Swift", defined_in="AmazonChimeSDK",generated_declaration))), apply_to=any(function,enum,objc_interface,objc_category,objc_protocol))
# pragma pop_macro("any")
#endif

#if defined(__OBJC__)
@class AVAudioSessionPortDescription;
@class AVAudioSessionRouteDescription;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK12AudioSession_")
@protocol AudioSession
@property (nonatomic, readonly) AVAudioSessionRecordPermission recordPermission;
@property (nonatomic, readonly, copy) NSArray<AVAudioSessionPortDescription *> * _Nullable availableInputs;
- (BOOL)setPreferredInput:(AVAudioSessionPortDescription * _Nullable)inPort error:(NSError * _Nullable * _Nullable)error;
- (BOOL)overrideOutputAudioPort:(AVAudioSessionPortOverride)portOverride error:(NSError * _Nullable * _Nullable)error;
@property (nonatomic, readonly, strong) AVAudioSessionRouteDescription * _Nonnull currentRoute;
@end


@interface AVAudioSession (SWIFT_EXTENSION(AmazonChimeSDK)) <AudioSession>
@end

@protocol ActiveSpeakerPolicy;
@protocol ActiveSpeakerObserver;

/// <code>ActiveSpeakerDetectorFacade</code> listens to the volume indicator updates from the <code>RealtimeControllerFacade</code>.
/// It consults the <code>ActiveSpeakerPolicy</code> to determine if the speaker is active or not.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK27ActiveSpeakerDetectorFacade_")
@protocol ActiveSpeakerDetectorFacade
/// Starts the active speaker detector on the callback for the given policy.
/// \param policy Handles Active Speaker implementation
///
/// \param observer Observer that handles Active Speaker Events
///
- (void)addActiveSpeakerObserverWithPolicy:(id <ActiveSpeakerPolicy> _Nonnull)policy observer:(id <ActiveSpeakerObserver> _Nonnull)observer;
/// Stops the active speaker detector callback from being called.
/// \param observer Observer that handles Active Speaker Events
///
- (void)removeActiveSpeakerObserverWithObserver:(id <ActiveSpeakerObserver> _Nonnull)observer;
/// Handles bandwidth
/// \param hasBandwidthPriority Tells the active speaker detector
/// whether or not to prioritize video bandwidth for active speakers
///
- (void)hasBandwidthPriorityCallbackWithHasBandwidthPriority:(BOOL)hasBandwidthPriority;
@end

@class NSString;
@class AttendeeInfo;

/// <code>ActiveSpeakerObserver</code> handles event related to finding active speaker and corresponding scores
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK21ActiveSpeakerObserver_")
@protocol ActiveSpeakerObserver
/// Uniquely identifies this observer
@property (nonatomic, readonly, copy) NSString * _Nonnull observerId;
@optional
/// Frequency of activeSpeakerScoreDidChange
@property (nonatomic, readonly) NSInteger scoresCallbackIntervalMs;
/// Observes the active speaker scores at frequency scoresCallbackIntervalMs
/// Note: this callback will be called on main thread.
/// Note: this callback will NOT be called unless scoresCallbackIntervalMs was set
/// \param scores Active speaker scores for each attendee
///
- (void)activeSpeakerScoreDidChangeWithScores:(NSDictionary<AttendeeInfo *, NSNumber *> * _Nonnull)scores;
@required
/// Observes changes in list of active speakers
/// Note: this callback will be called on main thread.
/// \param attendeeInfo List of active speakers in decreasing order of score
///
- (void)activeSpeakerDidDetectWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
@end

enum VolumeLevel : NSInteger;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19ActiveSpeakerPolicy_")
@protocol ActiveSpeakerPolicy
/// Return the score of the speaker. If the score is 0, this speaker is not active.
/// \param attendeeInfo Attendee to calculate the score for
///
/// \param volume Volume level of the speaker
///
///
/// returns:
/// The score of the speaker. The higher score, the more active the speaker.
- (double)calculateScoreWithAttendeeInfo:(AttendeeInfo * _Nonnull)attendeeInfo volume:(enum VolumeLevel)volume SWIFT_WARN_UNUSED_RESULT;
/// Indicates whether the audio video controller is allowed to increase video send bandwidth
/// for the currently active speaker if they have an active video tile. Set this to true, if
/// your application makes the active speaker video tile larger than the other tiles.
///
/// returns:
/// Whether to prioritize video bandwidth for active speakers
- (BOOL)prioritizeVideoSendBandwidthForActiveSpeaker SWIFT_WARN_UNUSED_RESULT;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK8Attendee")
@interface Attendee : NSObject
- (nonnull instancetype)initWithAttendeeId:(NSString * _Nonnull)attendeeId externalUserId:(NSString * _Nonnull)externalUserId joinToken:(NSString * _Nonnull)joinToken OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK12AttendeeInfo")
@interface AttendeeInfo : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull attendeeId;
@property (nonatomic, readonly, copy) NSString * _Nonnull externalUserId;
- (nonnull instancetype)initWithAttendeeId:(NSString * _Nonnull)attendeeId externalUserId:(NSString * _Nonnull)externalUserId OBJC_DESIGNATED_INITIALIZER;
- (BOOL)isEqual:(id _Nullable)object SWIFT_WARN_UNUSED_RESULT;
@property (nonatomic, readonly) NSUInteger hash;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// <code>AttendeeStatus</code> describes the status of attendee
typedef SWIFT_ENUM(NSInteger, AttendeeStatus, open) {
/// The attendee joined
  AttendeeStatusJoined = 1,
/// The attendee left
  AttendeeStatusLeft = 2,
/// The attendee dropped due to network issues
  AttendeeStatusDropped = 3,
};

@class AppInfo;
@protocol AudioClientDelegate;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19AudioClientProtocol_")
@protocol AudioClientProtocol
- (audio_client_status_t)startSession:(NSString * _Null_unspecified)host basePort:(NSInteger)port callId:(NSString * _Null_unspecified)callId profileId:(NSString * _Null_unspecified)profileId microphoneMute:(BOOL)mic_mute speakerMute:(BOOL)spk_mute isPresenter:(BOOL)presenter sessionToken:(NSString * _Null_unspecified)tokenString audioWsUrl:(NSString * _Null_unspecified)audioWsUrl callKitEnabled:(BOOL)callKitEnabled appInfo:(AppInfo * _Null_unspecified)appInfo SWIFT_WARN_UNUSED_RESULT;
- (audio_client_status_t)startSession:(NSString * _Null_unspecified)host basePort:(NSInteger)port callId:(NSString * _Null_unspecified)callId profileId:(NSString * _Null_unspecified)profileId microphoneMute:(BOOL)mic_mute speakerMute:(BOOL)spk_mute isPresenter:(BOOL)presenter sessionToken:(NSString * _Null_unspecified)tokenString audioWsUrl:(NSString * _Null_unspecified)audioWsUrl callKitEnabled:(BOOL)callKitEnabled appInfo:(AppInfo * _Null_unspecified)appInfo audioMode:(AudioModeInternal)audioMode SWIFT_WARN_UNUSED_RESULT;
- (audio_client_status_t)startSession:(NSString * _Null_unspecified)host basePort:(NSInteger)port callId:(NSString * _Null_unspecified)callId profileId:(NSString * _Null_unspecified)profileId microphoneMute:(BOOL)mic_mute speakerMute:(BOOL)spk_mute isPresenter:(BOOL)presenter sessionToken:(NSString * _Null_unspecified)tokenString audioWsUrl:(NSString * _Null_unspecified)audioWsUrl callKitEnabled:(BOOL)callKitEnabled SWIFT_WARN_UNUSED_RESULT;
- (NSInteger)stopSession SWIFT_WARN_UNUSED_RESULT;
- (BOOL)isSpeakerOn SWIFT_WARN_UNUSED_RESULT;
- (BOOL)setSpeakerOn:(BOOL)value SWIFT_WARN_UNUSED_RESULT;
- (NSInteger)stopAudioRecord SWIFT_WARN_UNUSED_RESULT;
- (BOOL)isMicrophoneMuted SWIFT_WARN_UNUSED_RESULT;
- (NSInteger)setMicrophoneMuted:(BOOL)mute SWIFT_WARN_UNUSED_RESULT;
- (void)setPresenter:(BOOL)presenter;
- (void)remoteMute;
- (void)audioLogCallBack:(loglevel_t)logLevel msg:(NSString * _Null_unspecified)msg;
- (BOOL)isBliteNSSelected SWIFT_WARN_UNUSED_RESULT;
- (NSInteger)setBliteNSSelected:(BOOL)bliteSelected SWIFT_WARN_UNUSED_RESULT;
- (void)endOnHold;
- (void)joinPrimaryMeeting:(NSString * _Null_unspecified)attendeeId externalUserId:(NSString * _Null_unspecified)externalUserId joinToken:(NSString * _Null_unspecified)joinToken;
- (void)leavePrimaryMeeting;
@property (nonatomic, strong) id <AudioClientDelegate> _Null_unspecified delegate;
@end


@interface AudioClient (SWIFT_EXTENSION(AmazonChimeSDK)) <AudioClientProtocol>
@end

enum AudioMode : NSInteger;
@class MeetingSessionCredentials;
@protocol PrimaryMeetingPromotionObserver;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK21AudioClientController_")
@protocol AudioClientController
- (BOOL)setMuteWithMute:(BOOL)mute SWIFT_WARN_UNUSED_RESULT;
- (BOOL)startWithAudioFallbackUrl:(NSString * _Nonnull)audioFallbackUrl audioHostUrl:(NSString * _Nonnull)audioHostUrl meetingId:(NSString * _Nonnull)meetingId attendeeId:(NSString * _Nonnull)attendeeId joinToken:(NSString * _Nonnull)joinToken callKitEnabled:(BOOL)callKitEnabled audioMode:(enum AudioMode)audioMode error:(NSError * _Nullable * _Nullable)error;
- (void)stop;
- (BOOL)setVoiceFocusEnabledWithEnabled:(BOOL)enabled SWIFT_WARN_UNUSED_RESULT;
- (BOOL)isVoiceFocusEnabled SWIFT_WARN_UNUSED_RESULT;
- (void)promoteToPrimaryMeetingWithCredentials:(MeetingSessionCredentials * _Nonnull)credentials observer:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
- (void)demoteFromPrimaryMeeting;
@end

@protocol AudioVideoObserver;
@protocol RealtimeObserver;
@protocol TranscriptEventObserver;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19AudioClientObserver_")
@protocol AudioClientObserver
- (void)notifyAudioClientObserverWithObserverFunction:(void (^ _Nonnull)(id <AudioVideoObserver> _Nonnull))observerFunction;
- (void)subscribeToAudioClientStateChangeWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)subscribeToRealTimeEventsWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)unsubscribeFromAudioClientStateChangeWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)unsubscribeFromRealTimeEventsWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)subscribeToTranscriptEventWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (void)unsubscribeFromTranscriptEventWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (void)setPrimaryMeetingPromotionObserverWithObserver:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
@end



SWIFT_PROTOCOL("_TtP14AmazonChimeSDK9AudioLock_")
@protocol AudioLock
- (void)lock;
- (void)unlock;
@end

/// <code>AudioMode</code> describes the audio mode in which the audio client should operate during a meeting session
typedef SWIFT_ENUM(NSInteger, AudioMode, open) {
/// The mono audio mode with single audio channel and 16KHz sampling rate, for both speaker and microphone.
  AudioModeMono16K = 1,
/// The mono audio mode with single audio channel and 48KHz sampling rate, for both speaker and microphone.
  AudioModeMono48K = 2,
/// The stereo audio mode with two audio channels for speaker, and single audio channel for microphone, both with 48KHz sampling rate.
  AudioModeStereo48K = 3,
  AudioModeNodevice = 4,
};



/// <code>AudioVideoConfiguration</code> represents the configuration to be used for audio and video during a meeting session.
SWIFT_CLASS("_TtC14AmazonChimeSDK23AudioVideoConfiguration")
@interface AudioVideoConfiguration : NSObject
@property (nonatomic, readonly) enum AudioMode audioMode;
@property (nonatomic, readonly) BOOL callKitEnabled;
- (nonnull instancetype)init;
- (nonnull instancetype)initWithAudioMode:(enum AudioMode)audioMode;
- (nonnull instancetype)initWithCallKitEnabled:(BOOL)callKitEnabled;
- (nonnull instancetype)initWithAudioMode:(enum AudioMode)audioMode callKitEnabled:(BOOL)callKitEnabled OBJC_DESIGNATED_INITIALIZER;
@end

@class MeetingSessionConfiguration;
@protocol Logger;
@class LocalVideoConfiguration;
@protocol VideoSource;
@protocol MetricsObserver;
@class RemoteVideoSource;
@class VideoSubscriptionConfiguration;

/// <code>AudioVideoControllerFacade</code> manages the signaling and peer connections.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK26AudioVideoControllerFacade_")
@protocol AudioVideoControllerFacade
@property (nonatomic, readonly, strong) MeetingSessionConfiguration * _Nonnull configuration;
@property (nonatomic, readonly, strong) id <Logger> _Nonnull logger;
/// Start AudioVideo Controller
/// \param audioVideoConfiguration The configuration used for Audio & Video
///
///
/// throws:
/// <code>MediaError.illegalState</code> if audio client is already started before calling start()
- (BOOL)startWithAudioVideoConfiguration:(AudioVideoConfiguration * _Nonnull)audioVideoConfiguration error:(NSError * _Nullable * _Nullable)error;
/// Start AudioVideo Controller
/// \param callKitEnabled A Bool value to indicate whether the VoIP call to start has CallKit integration.
/// This parameter is used to determine how audio session interruptions should be handled,
/// in scenarios such as receving another phone call during the VoIP call.
///
///
/// throws:
/// <code>MediaError.illegalState</code> if audio client is already started before calling start()
- (BOOL)startWithCallKitEnabled:(BOOL)callKitEnabled error:(NSError * _Nullable * _Nullable)error;
/// Start AudioVideo Controller
///
/// throws:
/// <code>MediaError.illegalState</code> if audio client is already started before calling start()
- (BOOL)startAndReturnError:(NSError * _Nullable * _Nullable)error;
/// Stop AudioVideo Controller. This will exit the meeting
- (void)stop;
/// Start local video and begin transmitting frames from an internally held <code>DefaultCameraCaptureSource</code>.
/// <code>stopLocalVideo</code> will stop the internal capture source if being used.
/// Calling this after passing in a custom <code>VideoSource</code> will replace it with the internal capture source.
/// This function will only have effect if <code>start</code> has already been called
///
/// throws:
/// <code>PermissionError.videoPermissionError</code> if video permission of <code>AVCaptureDevice</code> is not granted
- (BOOL)startLocalVideoAndReturnError:(NSError * _Nullable * _Nullable)error;
/// Start local video with configurations and begin transmitting frames from an internally held <code>DefaultCameraCaptureSource</code>.
/// <code>stopLocalVideo</code> will stop the internal capture source if being used.
/// Calling this after passing in a custom <code>VideoSource</code> will replace it with the internal capture source.
/// This function will only have effect if <code>start</code> has already been called
/// If maxBitRateKbps is not set, it will be self adjusted depending on number of users and videos in the meeting
/// \param config configurations of emitted video stream, e.g. simulcast, maxBitRateKbps
///
///
/// throws:
/// <code>PermissionError.videoPermissionError</code> if video permission of <code>AVCaptureDevice</code> is not granted
- (BOOL)startLocalVideoWithConfig:(LocalVideoConfiguration * _Nonnull)config error:(NSError * _Nullable * _Nullable)error;
/// Start local video with a provided custom <code>VideoSource</code> which can be used to provide custom
/// <code>VideoFrame</code>s to be transmitted to remote clients. This will call <code>VideoSource.addVideoSink</code>
/// on the provided source.
/// Calling this function repeatedly will replace the previous <code>VideoSource</code> as the one being
/// transmitted. It will also stop and replace the internal capture source if <code>startLocalVideo</code>
/// was previously called with no arguments.
/// This function will only have effect if <code>start</code> has already been called
/// \param source The source of video frames to be sent to other clients
///
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source;
/// Start local video with configurations and a provided custom <code>VideoSource</code> which can be used to provide custom
/// <code>VideoFrame</code>s to be transmitted to remote clients. This will call <code>VideoSource.addVideoSink</code>
/// on the provided source.
/// Calling this function repeatedly will replace the previous <code>VideoSource</code> as the one being
/// transmitted. It will also stop and replace the internal capture source if <code>startLocalVideo</code>
/// was previously called with no arguments.
/// This function will only have effect if <code>start</code> has already been called
/// If maxBitRateKbps is not set, it will be self adjusted depending on number of users and videos in the meeting
/// \param source The source of video frames to be sent to other clients
///
/// \param config Configurations of emitted video stream, e.g. simulcast, maxBitRateKbps
///
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
/// Stops sending video for local attendee. This will additionally stop the internal capture source if being used.
/// If using a custom video source, this will call <code>VideoSource.removeVideoSink</code> on the previously provided source.
- (void)stopLocalVideo;
/// Enable remote video to start receiving streams
- (void)startRemoteVideo;
/// Disable remote video to stop receiving streams
- (void)stopRemoteVideo;
/// Subscribe to audio, video, and connection events with an <code>AudioVideoObserver</code>.
/// \param observer The observer to subscribe to events with
///
- (void)addAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
/// Unsubscribes from audio, video, and connection events by removing specified <code>AudioVideoObserver</code>.
/// \param observer The observer to unsubscribe from events with
///
- (void)removeAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
/// Subscribe to metrics events with an <code>MetricsObserver</code>.
/// \param observer The observer to subscribe to events with
///
- (void)addMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
/// Unsubscribes from metrics events by removing specified <code>MetricsObserver</code>.
/// \param observer The observer to unsubscribe from events with
///
- (void)removeMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
/// Add, update, or remove subscriptions to remote video sources provided via <code>remoteVideoSourcesDidBecomeAvailable</code>.
/// This function requires using the <code>RemoteVideoSource</code> provided by <code>remoteVideoSourcesDidBecomeAvailable</code>, otherwise it will not update properly.
/// This is what allows to use the <code>RemoteVideoSource</code> objects as keys in a map.
/// Including a <code>RemoteVideoSource</code> in <code>addedOrUpdated</code> which was not previously provided will result in the negotiation of media flow for that source. After negotiation has
/// completed,<code>videoTileDidAdd</code> on the tile controller will be called with the <code>TileState</code> of the source, and applications
/// can render the video via ‘bindVideoTile’. Reincluding a <code>RemoteVideoSource</code> can be done to update the provided <code>VideoSubscriptionConfiguration</code>,
/// but it is not necessary to continue receiving frames.
/// Including a <code>RemoteVideoSource</code> in <code>removed</code> will stop the flow video from that source, and lead to a <code>videoTileDidRemove</code> call on the
/// tile controller to indicate to the application that the tile should be unbound. To restart the flow of media, the source should be re-added by
/// including in <code>addedOrUpdated</code>. Note that videos no longer available in a meeting (i.e. listed in
/// <code>remoteVideoSourcesDidBecomeUnavailable</code> do not need to be removed, as they will be automatically unsubscribed from.
/// Note that before this function is called for the first time, the client will automatically subscribe to all video sources.
/// However this behavior will cease upon first call (e.g. if there are 10 videos in the meeting, the controller will subscribe to all 10, however if
/// <code>updateVideoSourceSubscriptions</code> is called with a single video in <code>addedOrUpdated</code>, the client will unsubscribe from the other 9.
/// This automatic subscription behavior may be removed in future major version updates, builders should avoid relying on the logic
/// and instead explicitly call <code>updateVideoSourceSubscriptions</code> with the sources they want to receive.
/// \param addedOrUpdated Dictionary of remote video sources to configurations to add or update
///
/// \param removed Array of remote video sources to remove
///
- (void)updateVideoSourceSubscriptionsWithAddedOrUpdated:(NSDictionary<RemoteVideoSource *, VideoSubscriptionConfiguration *> * _Nonnull)addedOrUpdated removed:(NSArray<RemoteVideoSource *> * _Nonnull)removed;
/// Allows an attendee in a Replica meeting to immediately transition to a Primary meeting attendee
/// without need for reconnection.
/// <code>PrimaryMeetingPromotionObserver.didPromoteToPrimaryMeeting</code> will be called exactly once on <code>observer</code> for each call. If
/// the promotion is successful,  <code>PrimaryMeetingPromotionObserver.didDemoteFromPrimaryMeeting</code> will be called exactly once
/// if/when the attendee is demoted. See the observer documentation for possible status codes.
/// Application code may also receive a callback on <code>AudioVideoObserver.videoSessionDidStartWithStatus</code> without
/// <code>MeetingSessionStatusCode.VideoAtCapacityViewOnly</code> to indicate they can begin to share video.
/// <code>chime::DeleteAttendee</code> on the Primary meeting attendee will result in <code>PrimaryMeetingPromotionObserver.didDemoteFromPrimaryMeeting</code>
/// to indicate the attendee is no longer able to share.
/// Any disconnection will trigger an automatic demotion to avoid unexpected or unwanted promotion state on reconnection.
/// This will also call <code>PrimaryMeetingPromotionObserver.didDemoteFromPrimaryMeeting</code>;  if the attendee still needs to be
/// an interactive participant in the Primary meeting, <code>promoteToPrimaryMeeting</code> should be called again with the same credentials.
/// Note that given the asynchronous nature of this function, this should not be called a second time before
/// <code>PrimaryMeetingPromotionObserver.didPromoteToPrimaryMeeting</code> is called for the first time. Doing so may result in unexpected
/// behavior.
/// \param credentials The credentials for the primary meeting.  This needs to be obtained out of band.
///
/// \param observer Will be called with a session status for the request and possible demotion. See possible options above.
///
- (void)promoteToPrimaryMeetingWithCredentials:(MeetingSessionCredentials * _Nonnull)credentials observer:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
/// Remove the promoted attendee from the Primary meeting. This client will stop sharing audio, video, and data messages.
/// This will revert the end-user to precisely the state they were before a call to <code>promoteToPrimaryMeeting</code>
/// This will have no effect if there was no previous successful call to <code>promoteToPrimaryMeeting</code>. This
/// may result in <code>PrimaryMeetingPromotionObserver.didPromoteToPrimaryMeeting</code> but there is no need to wait for that callback
/// to revert UX, etc.
- (void)demoteFromPrimaryMeeting;
@end

@protocol EventAnalyticsObserver;
@class MeetingHistoryEvent;

/// <code>EventAnalyticsFacade</code> exposes event analytics related function to builders
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK20EventAnalyticsFacade_")
@protocol EventAnalyticsFacade
/// Subscribes to meeting event related data with an observer
/// \param observer An observer to add to start receiving meeting events
///
- (void)addEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
/// Unsubscribes from meeting event by removing the specified observer
/// \param observer An observer to remove to stop receiving meeting events
///
- (void)removeEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
/// Retrieve meeting history.
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
/// Retrieve common attributes, including deviceName, osName, and more.
- (NSDictionary * _Nonnull)getCommonEventAttributes SWIFT_WARN_UNUSED_RESULT;
@end

@class ContentShareSource;
@protocol ContentShareObserver;

/// <code>ContentShareController</code> exposes methods for starting and stopping content share with a <code>ContentShareSource</code>.
/// The content represents a media steam to be shared in the meeting, such as screen capture or media files.
/// Please refer to <a href="https://github.com/aws/amazon-chime-sdk-ios/blob/master/guides/content_share.md">content share guide</a> for details.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK22ContentShareController_")
@protocol ContentShareController
/// Start sharing the content of a given <code>ContentShareSource</code>.
/// Once sharing has started successfully, <code>ContentShareObserver.contentShareDidStart</code> will
/// be notified. If sharing fails or stops, <code>ContentShareObserver.contentShareDidStop</code>
/// will be invoked with <code>ContentShareStatus</code> as the cause.
/// This will call <code>VideoSource.addVideoSink(sink:)</code> on the provided source
/// and <code>VideoSource.removeVideoSink(sink:)</code> on the previously provided source.
/// Calling this function repeatedly will replace the previous <code>ContentShareSource</code> as the one being transmitted.
/// \param source source of content to be shared
///
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source;
/// Start sharing the content of a given <code>ContentShareSource</code>, with configurations.
/// Once sharing has started successfully, <code>ContentShareObserver.contentShareDidStart</code> will
/// be notified. If sharing fails or stops, <code>ContentShareObserver.contentShareDidStop</code>
/// will be invoked with <code>ContentShareStatus</code> as the cause.
/// This will call <code>VideoSource.addVideoSink(sink:)</code> on the provided source
/// and <code>VideoSource.removeVideoSink(sink:)</code> on the previously provided source.
/// Calling this function repeatedly will replace the previous <code>ContentShareSource</code> as the one being transmitted.
/// \param source source of content to be shared
///
/// \param config configurations of emitted video stream, e.g maxBitRateKbps
///
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
/// Stop sharing the content of a <code>ContentShareSource</code> that previously started.
/// Once the sharing stops successfully, <code>ContentShareObserver.contentShareDidStop</code>
/// will be invoked with status code <code>ContentShareStatusCode.OK</code>.
- (void)stopContentShare;
/// Subscribe the given observer to content share events (sharing started and stopped).
/// \param observer observer to be notified for events
///
- (void)addContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
/// Unsubscribe the given observer from content share events.
/// \param observer observer to be removed for events
///
- (void)removeContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
@end

@protocol VideoRenderView;
@protocol VideoTileObserver;

/// <code>VideoTileControllerFacade</code> allows one to control <code>VideoTile</code>. The caller is responsible for laying
/// out video render views as desired and binding tile ids received from the observer
/// in the <code>videoTileDidAdd</code> and <code>videoTileDidRemove</code> callbacks.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK25VideoTileControllerFacade_")
@protocol VideoTileControllerFacade
/// Binds the video rendering view to Video Tile. The view will start displaying the video frame
/// after the completion of this API
/// \param videoView View to render the video. Application needs to create it and pass to SDK.
///
/// \param tileId id of the tile which was passed to the application in <code>VideoTileObserver.videoTileDidAdd</code>
///
- (void)bindVideoViewWithVideoView:(id <VideoRenderView> _Nonnull)videoView tileId:(NSInteger)tileId;
/// Unbinds the video rendering view from Video Tile. The view will stop displaying the video frame
/// after the completion of this API
/// \param tileId id of the tile which was passed to the application in <code>VideoTileObserver.videoTileDidRemove</code>
///
- (void)unbindVideoViewWithTileId:(NSInteger)tileId;
/// Subscribe to Video Tile events with an <code>VideoTileObserver</code>.
/// \param observer The observer to subscribe to events with
///
- (void)addVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
/// Unsubscribes from Video Tile events by removing specified <code>VideoTileObserver</code>.
/// \param observer The observer to unsubscribe from events with
///
- (void)removeVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
/// Pauses remote video tile, if it exists.
/// \param tileId The tile id to pause
///
- (void)pauseRemoteVideoTileWithTileId:(NSInteger)tileId;
/// Resume remote video tile, if it exists.
/// \param tileId The tile id to resume
///
- (void)resumeRemoteVideoTileWithTileId:(NSInteger)tileId;
@end

@class MediaDevice;
@protocol DeviceChangeObserver;

/// <code>DeviceController</code> keeps track of the devices being used for audio device
/// (e.g. built-in speaker), video input (e.g. camera)).
/// The list functions return <code>MediaDevice</code> objects.
/// Changes in device availability are broadcast to any registered
/// <code>DeviceChangeObserver</code>.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK16DeviceController_")
@protocol DeviceController
/// List available audio devices
///
/// returns:
/// list of Media Devices
- (NSArray<MediaDevice *> * _Nonnull)listAudioDevices SWIFT_WARN_UNUSED_RESULT;
/// Choose audio devices
/// \param mediaDevice the device used as audio route
///
- (void)chooseAudioDeviceWithMediaDevice:(MediaDevice * _Nonnull)mediaDevice;
/// Add device change observer
/// \param observer the object that will receive notification
///
- (void)addDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
/// Remove device change observer
/// \param observer the object that will be removed
///
- (void)removeDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
/// Switch between front/back camera. This will no-op if using a custom source,
/// e.g. one passed in via <code>startLocalVideo</code>
- (void)switchCamera;
/// Get the currently active camera, if any. This will return null if using a custom source,
/// e.g. one passed in via <code>AudioVideoControllerFacade.startLocalVideo</code>
///
/// returns:
/// a media device or nil if no device is present
- (MediaDevice * _Nullable)getActiveCamera SWIFT_WARN_UNUSED_RESULT;
/// Get currently used audio device
///
/// returns:
/// a media device or nil if no device is present
- (MediaDevice * _Nullable)getActiveAudioDevice SWIFT_WARN_UNUSED_RESULT;
@end

@protocol DataMessageObserver;

/// <code>RealtimeControllerFacade</code> controls aspects meetings concerning realtime UX
/// that for performance, privacy, or other reasons should be implemented using
/// the most direct path. Callbacks generated by this interface should be
/// consumed synchronously and without business logic dependent on the UI state
/// where possible.
/// Events will be passed through <code>RealtimeObserver</code>, which in turn provides consumers the
/// volume/mute/signal/attendee callbacks that can be used to render in the UI.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK24RealtimeControllerFacade_")
@protocol RealtimeControllerFacade
/// Mutes the audio input.
///
/// returns:
/// Whether mute was successful
- (BOOL)realtimeLocalMute SWIFT_WARN_UNUSED_RESULT;
/// Unmutes the audio input if currently allowed
///
/// returns:
/// Whether unmute was successful
- (BOOL)realtimeLocalUnmute SWIFT_WARN_UNUSED_RESULT;
/// Subscribes to real time events with an observer
/// \param observer Observer that handles real time events
///
- (void)addRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
/// Unsubscribes from real time events by removing the specified observer
/// \param observer Observer that handles real time events
///
- (void)removeRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
/// Subscribes to data meesage event with an observer
/// \param topic Topic to handle
///
/// \param observer Observer that handles data message event with given topic
///
- (void)addRealtimeDataMessageObserverWithTopic:(NSString * _Nonnull)topic observer:(id <DataMessageObserver> _Nonnull)observer;
/// Unsubscribes from data meesage event by removing the specified observer by topic
/// \param topic Topic to remove
///
- (void)removeRealtimeDataMessageObserverFromTopicWithTopic:(NSString * _Nonnull)topic;
/// Send arbitrary data to given topic with given lifetime ms (5 mins max)
/// \param topic Topic to send
///
/// \param data Data to send, data can be a String, a ByteArray, or a JSON serializable object
///
/// \param lifetimeMs Message lifetime in milisecond, 5 mins max, default 0
///
///
/// throws:
/// SendDataMessageError
- (BOOL)realtimeSendDataMessageWithTopic:(NSString * _Nonnull)topic data:(id _Nonnull)data lifetimeMs:(int32_t)lifetimeMs error:(NSError * _Nullable * _Nullable)error;
/// Enable or disable Amazon Voice Focus (ML-based noise suppression) on the audio input
/// Note: Only call this API after audioClient starts. Calling it before that results in a no-op. Amazon Voice Focus is disabled by default when audioClient starts.
/// \param enabled A <code>Bool</code> value, where <code>true</code> to enable; <code>false</code> to disable
///
///
/// returns:
/// Whether the enable/disable action was successful
- (BOOL)realtimeSetVoiceFocusEnabledWithEnabled:(BOOL)enabled SWIFT_WARN_UNUSED_RESULT;
/// Check if Amazon Voice Focus (ML-based noise suppression) is enabled or not
///
/// returns:
/// <code>true</code> if Amazon Voice Focus is enabled; <code>false</code> if Amazon Voice Focus is not enabled, or the audio session was not started yet
- (BOOL)realtimeIsVoiceFocusEnabled SWIFT_WARN_UNUSED_RESULT;
@optional
/// Subscribe to live transcription events with an observer
/// \param observer Observer that handles live transcription events
///
- (void)addRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
/// Unsubscribes from live transcription events by removing the specified observer
/// \param observer Observer that handles live transcription events
///
- (void)removeRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
@end


SWIFT_PROTOCOL("_TtP14AmazonChimeSDK16AudioVideoFacade_")
@protocol AudioVideoFacade <ActiveSpeakerDetectorFacade, AudioVideoControllerFacade, ContentShareController, DeviceController, EventAnalyticsFacade, RealtimeControllerFacade, VideoTileControllerFacade>
@end

@class MeetingSessionStatus;

/// <code>AudioVideoObserver</code> handles audio/video session events.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK18AudioVideoObserver_")
@protocol AudioVideoObserver
/// Called when the audio session is connecting or reconnecting.
/// Note: this callback will be called on main thread.
/// \param reconnecting Whether the session is reconnecting or not.
///
- (void)audioSessionDidStartConnectingWithReconnecting:(BOOL)reconnecting;
/// Called when the audio session has started.
/// Note: this callback will be called on main thread.
/// \param reconnecting Whether the session is reconnecting or not.
///
- (void)audioSessionDidStartWithReconnecting:(BOOL)reconnecting;
/// Called when audio session got dropped due to poor network conditions.
/// There will be an automatic attempt of reconnecting it.
/// If the reconnection is successful, <code>onAudioSessionStarted</code> will be called with value of reconnecting as true
/// Note: this callback will be called on main thread.
- (void)audioSessionDidDrop;
/// Called when the audio session has stopped with the reason provided in the status.
/// This callback implies that audio client has stopped permanently for this session
/// and there will be no attempt of reconnecting it.
/// Note: this callback will be called on main thread.
/// \param sessionStatus The reason why the session has stopped.
///
- (void)audioSessionDidStopWithStatusWithSessionStatus:(MeetingSessionStatus * _Nonnull)sessionStatus;
/// Called when the audio reconnection is canceled.
/// Note: this callback will be called on main thread.
- (void)audioSessionDidCancelReconnect;
/// Called when the connection health is recovered.
/// Note: this callback will be called on main thread.
- (void)connectionDidRecover;
/// Called when connection is becoming poor.
/// Note: this callback will be called on main thread.
- (void)connectionDidBecomePoor;
/// Called when the video session is connecting or reconnecting.
/// Note: this callback will be called on main thread.
- (void)videoSessionDidStartConnecting;
/// Called when the video session has started.
/// Note: this callback will be called on main thread.
/// \param sessionStatus The status of meeting session
///
- (void)videoSessionDidStartWithStatusWithSessionStatus:(MeetingSessionStatus * _Nonnull)sessionStatus;
/// Called when the video session has stopped from a started state with the reason provided in the status.
/// Note: this callback will be called on main thread.
/// \param sessionStatus The reason why the session has stopped.
///
- (void)videoSessionDidStopWithStatusWithSessionStatus:(MeetingSessionStatus * _Nonnull)sessionStatus;
/// Called on the main thread when video sources become available.
/// Video sources can be explicitly subscribed to through <code>updateVideoSourceSubscriptions</code>.
/// These should be stored and used when <code>updateVideoSourceSubscriptions</code> is called (i.e. you cannot use <code>RemoteVideoSource</code> objects created manually).
/// See <code>updateVideoSourceSubscriptions</code> for more information.
/// See note in <code>updateVideoSourceSubscriptions</code> documentation for information on
/// subscription behavior if <code>updateVideoSourceSubscriptions</code> is never called.
/// \param sources Array of remote video sources that are available
///
- (void)remoteVideoSourcesDidBecomeAvailableWithSources:(NSArray<RemoteVideoSource *> * _Nonnull)sources;
/// Called on the main thread when video sources become unavailable.
/// Note that these sources do not need to be removed via <code>updateVideoSourceSubscriptions</code>,
/// as they will be automatically unsubscribed from.
/// \param sources Array of video sources that are unavailable
///
- (void)remoteVideoSourcesDidBecomeUnavailableWithSources:(NSArray<RemoteVideoSource *> * _Nonnull)sources;
/// Called on the main thread when video capacity status is updated.
/// \param available True if camera send is available (due to video capacity status), False if not.
///
- (void)cameraSendAvailabilityDidChangeWithAvailable:(BOOL)available;
@end

/// Enum defining the different background blur strength options.
typedef SWIFT_ENUM(NSInteger, BackgroundBlurStrength, open) {
  BackgroundBlurStrengthLow = 10,
  BackgroundBlurStrengthMedium = 15,
  BackgroundBlurStrengthHigh = 25,
};

/// Enum defining the different background filter options.
typedef SWIFT_ENUM(NSInteger, BackgroundFilter, open) {
  BackgroundFilterNone = 0,
  BackgroundFilterBlur = 1,
  BackgroundFilterReplacement = 2,
};

enum VideoContentHint : NSInteger;
@protocol VideoSink;

/// <code>VideoSource</code> is an interface for sources which produce video frames, and can send to a <code>VideoSink</code>.
/// Implementations can be passed to the <code>AudioVideoFacade</code> to be used as the video source sent to remote
/// participlants
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK11VideoSource_")
@protocol VideoSource
/// Content hint for downstream processing.
@property (nonatomic) enum VideoContentHint videoContentHint;
/// Add a video sink which will immediately begin to receive new frames.
/// Multiple sinks can be added to a single <code>VideoSource</code> to allow forking of video frames,
/// e.g. to send to both local preview and AmazonChimeSDKMedia framework (i.e. for encoding) at the same time.
/// \param sink New video sink
///
- (void)addVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
/// Remove a video sink which will no longer receive new frames on return.
/// \param sink Video sink to remove
///
- (void)removeVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
@end

@protocol CaptureSourceObserver;

/// <code>VideoCaptureSource</code> is an interface for various video capture sources (i.e. screen, camera, file) which can emit <code>VideoFrame</code> objects.
/// All the APIs in this protocol can be called regardless of whether the <code>MeetingSession.audioVideo</code> is started or not.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK18VideoCaptureSource_")
@protocol VideoCaptureSource <VideoSource>
/// Start capturing on this source and emitting video frames.
- (void)start;
/// Stop capturing on this source and cease emitting video frames.
- (void)stop;
/// Add a capture source observer to receive callbacks from the source on lifecycle events
/// which can be used to trigger UI. This observer is entirely optional.
/// \param observer - New observer.
///
- (void)addCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
/// Remove a capture source observer.
/// \param observer - Observer to remove.
///
- (void)removeCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
@end

@class VideoCaptureFormat;

/// <code>CameraCaptureSource</code> is an interface for camera capture sources with additional features
/// not covered by <code>VideoCaptureSource</code>.
/// All the APIs in this protocol can be called regardless of whether the <code>MeetingSession.audioVideo</code> is started or not.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19CameraCaptureSource_")
@protocol CameraCaptureSource <VideoCaptureSource>
/// Current camera device. This is only null if the phone/device doesn’t have any cameras
/// May be called regardless of whether <code>start</code> or <code>stop</code> has been called.
@property (nonatomic, strong) MediaDevice * _Nullable device;
/// Toggle for flashlight on the current device. Will succeed if current device has access to
/// flashlight, otherwise will stay <code>false</code>. May be called regardless of whether <code>start</code> or <code>stop</code>
/// has been called.
@property (nonatomic) BOOL torchEnabled;
/// Current camera capture format  Actual format may be adjusted to use supported camera formats.
/// May be called regardless of whether <code>start</code> or <code>stop</code> has been called.
@property (nonatomic, strong) VideoCaptureFormat * _Nonnull format;
/// Helper function to switch from front to back cameras or reverse.
- (void)switchCamera;
@end

/// <code>CaptureSourceError</code> describes an error resulting from a capture source failure.
/// These can be used to trigger UI, or attempt to restart the capture source.
typedef SWIFT_ENUM(NSInteger, CaptureSourceError, open) {
/// Unknown error, and catch-all for errors not otherwise covered.
  CaptureSourceErrorUnknown = 0,
/// A  failure observed from a system API used for capturing.
  CaptureSourceErrorSystemFailure = 1,
/// A failure observed during configuration.
  CaptureSourceErrorConfigurationFailure = 2,
/// A temporary failure observed when capture source generates an invalid frame which is ignored.
  CaptureSourceErrorInvalidFrame = 3,
};


/// <code>CaptureSourceObserver</code> observes events resulting from different types of capture devices.
/// Builders may desire this input to decide when to show certain UI elements, or to notify users of failure.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK21CaptureSourceObserver_")
@protocol CaptureSourceObserver
/// Called when the capture source has started successfully and has started emitting frames.
- (void)captureDidStart;
/// Called when the capture source has stopped when expected. This may occur when switching cameras, for example.
- (void)captureDidStop;
/// Called when the capture source failed permanently
/// \param error - The reason why the source has stopped.
///
- (void)captureDidFailWithError:(enum CaptureSourceError)error;
@end


/// ClientMetricsCollector takes the raw metrics from the native client,
/// consolidates them into a normalize map of ObservableMetric to value,
/// and eventually calls the OnReceiveMetric callback.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK22ClientMetricsCollector_")
@protocol ClientMetricsCollector
- (void)processAudioClientMetricsWithMetrics:(NSDictionary * _Nonnull)metrics;
- (void)processVideoClientMetricsWithMetrics:(NSDictionary * _Nonnull)metrics;
- (void)processContentShareVideoClientMetricsWithMetrics:(NSDictionary * _Nonnull)metrics;
- (void)subscribeToMetricsWithObserver:(id <MetricsObserver> _Nonnull)observer;
- (void)unsubscribeFromMetricsWithObserver:(id <MetricsObserver> _Nonnull)observer;
@end

enum LogLevel : NSInteger;

/// <code>Logger</code> defines how to write logs for different logging level.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK6Logger_")
@protocol Logger
/// Emits any message if the log level is equal to or lower than default level.
- (void)defaultWithMsg:(NSString * _Nonnull)msg;
/// Calls <code>debugFunction</code> only if the log level is debug and emits the
/// resulting string. Use the debug level to dump large or verbose messages
/// that could slow down performance.
- (void)debugWithDebugFunction:(SWIFT_NOESCAPE NSString * _Nonnull (^ _Nonnull)(void))debugFunction;
/// Emits an info message if the log level is equal to or lower than info level.
- (void)infoWithMsg:(NSString * _Nonnull)msg;
/// Emits a fault message if the log level is equal to or lower than fault level.
- (void)faultWithMsg:(NSString * _Nonnull)msg;
/// Emits an error message if the log level is equal to or lower than error level.
- (void)errorWithMsg:(NSString * _Nonnull)msg;
/// Sets the log level.
- (void)setLogLevelWithLevel:(enum LogLevel)level;
/// Gets the current log level.
- (enum LogLevel)getLogLevel SWIFT_WARN_UNUSED_RESULT;
@end


/// ConsoleLogger writes logs with console.
/// \code
/// // working with the ConsoleLogger
/// let logger = new ConsoleLogger("demo"); //default level is LogLevel.INFO
/// logger.info("info");
/// logger.debug("debug");
/// logger.fault("fault");
/// logger.error("error");
///
/// // setting logging levels
/// let logger = new ConsoleLogger("demo", .INFO);
/// logger.debug("debug"); // does not print
/// logger.setLogLevel(LogLevel.DEBUG)
/// logger.debug("debug"); // print
///
/// \endcode
SWIFT_CLASS("_TtC14AmazonChimeSDK13ConsoleLogger")
@interface ConsoleLogger : NSObject <Logger>
- (nonnull instancetype)initWithName:(NSString * _Nonnull)name level:(enum LogLevel)level OBJC_DESIGNATED_INITIALIZER;
- (void)defaultWithMsg:(NSString * _Nonnull)msg;
- (void)debugWithDebugFunction:(SWIFT_NOESCAPE NSString * _Nonnull (^ _Nonnull)(void))debugFunction;
- (void)infoWithMsg:(NSString * _Nonnull)msg;
- (void)faultWithMsg:(NSString * _Nonnull)msg;
- (void)errorWithMsg:(NSString * _Nonnull)msg;
- (void)setLogLevelWithLevel:(enum LogLevel)level;
- (enum LogLevel)getLogLevel SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


@class ContentShareStatus;

/// <code>ContentShareObserver</code> handles all callbacks related to the content share.
/// By implementing the callback functions and registering with <code>ContentShareController.addContentShareObserver</code>,
/// one can get notified with content share status events.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK20ContentShareObserver_")
@protocol ContentShareObserver
/// Called when the content share has started.
/// Note: this callback will be called on main thread.
- (void)contentShareDidStart;
/// Called when the content is no longer shared with other attendees with the reason provided in the status.
/// If you no longer need the source producing frames, stop the source after this callback is invoked.
/// Note: this callback will be called on main thread.
/// \param status the reason why the content share has stopped
///
- (void)contentShareDidStopWithStatus:(ContentShareStatus * _Nonnull)status;
@end


/// <code>ContentShareSource</code> contains the media sources to attach to the content share
SWIFT_CLASS("_TtC14AmazonChimeSDK18ContentShareSource")
@interface ContentShareSource : NSObject
@property (nonatomic, strong) id <VideoSource> _Nullable videoSource;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end

enum ContentShareStatusCode : NSInteger;

/// <code>ContentShareStatus</code> indicates a status received regarding the content share.
SWIFT_CLASS("_TtC14AmazonChimeSDK18ContentShareStatus")
@interface ContentShareStatus : NSObject
@property (nonatomic, readonly) enum ContentShareStatusCode statusCode;
- (nonnull instancetype)initWithStatusCode:(enum ContentShareStatusCode)statusCode OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// <code>ContentShareStatusCode</code> indicates the reason the content share event occurred.
typedef SWIFT_ENUM(NSInteger, ContentShareStatusCode, open) {
/// No failure.
  ContentShareStatusCodeOk = 0,
/// This can happen when the content share video connection is in an unrecoverable failed state.
/// Restart content share connection when this error is encountered.
  ContentShareStatusCodeVideoServiceFailed = 1,
};


SWIFT_PROTOCOL("_TtP14AmazonChimeSDK33ContentShareVideoClientController_")
@protocol ContentShareVideoClientController
- (void)startVideoShareWithSource:(id <VideoSource> _Nonnull)source;
- (void)startVideoShareWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopVideoShare;
- (void)subscribeToVideoClientStateChangeWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (void)unsubscribeFromVideoClientStateChangeWithObserver:(id <ContentShareObserver> _Nonnull)observer;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK22CreateAttendeeResponse")
@interface CreateAttendeeResponse : NSObject
- (nonnull instancetype)initWithAttendee:(Attendee * _Nonnull)attendee OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class Meeting;

SWIFT_CLASS("_TtC14AmazonChimeSDK21CreateMeetingResponse")
@interface CreateMeetingResponse : NSObject
- (nonnull instancetype)initWithMeeting:(Meeting * _Nonnull)meeting OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class NSData;

/// Data message received from server.
SWIFT_CLASS("_TtC14AmazonChimeSDK11DataMessage")
@interface DataMessage : NSObject
/// Monotonically increasing server ingest time
@property (nonatomic, readonly) int64_t timestampMs;
/// Topic this message was sent on
@property (nonatomic, readonly, copy) NSString * _Nonnull topic;
/// Data payload
@property (nonatomic, readonly, copy) NSData * _Nonnull data;
/// Sender attendee
@property (nonatomic, readonly, copy) NSString * _Nonnull senderAttendeeId;
/// Sender attendee external user Id
@property (nonatomic, readonly, copy) NSString * _Nonnull senderExternalUserId;
/// true if server throttled or rejected message,
/// false if server has posted the message to its recipients or it’s not a sender receipt
@property (nonatomic, readonly) BOOL throttled;
/// Initiailize a DataMessage object
/// \param topic The topic of this data message belongs to
///
/// \param data Data payload
///
/// \param senderAttendeeId Attendee Id
///
/// \param senderExternalUserId Attendee external user ID
///
/// \param timestampMs Monotonically increasing server ingest time
///
/// \param throttled if server throttled or rejected message
///
- (nonnull instancetype)initWithTopic:(NSString * _Nonnull)topic data:(NSData * _Nonnull)data senderAttendeeId:(NSString * _Nonnull)senderAttendeeId senderExternalUserId:(NSString * _Nonnull)senderExternalUserId timestampMs:(int64_t)timestampMs throttled:(BOOL)throttled OBJC_DESIGNATED_INITIALIZER;
/// Marshal data byte array to String
///
/// returns:
/// utf8 encoding string of data, null if data contains non utf8 characters
- (NSString * _Nullable)text SWIFT_WARN_UNUSED_RESULT;
/// Try deserialize data byte array to swift basic collection type
///
/// returns:
/// null if not deserializable, or swift basic collection type
- (id _Nullable)fromJSON SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>DataMessasgeObserver</code> handles data message event,
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19DataMessageObserver_")
@protocol DataMessageObserver
/// Handles data message receive event
/// Note: this callback will be called on main thread.
/// \param dataMessage The data message received
///
- (void)dataMessageDidReceivedWithDataMessage:(DataMessage * _Nonnull)dataMessage;
@end

@class VolumeUpdate;
@class SignalUpdate;

/// <code>RealtimeObserver</code> handles event that happens in realtime,
/// such as delta in attendees join or leave, volume/signal status.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK16RealtimeObserver_")
@protocol RealtimeObserver
/// Handles volume changes for attendees
/// Note: this callback will be called on main thread.
/// \param volumeUpdates An array of VolumeUpdates
///
- (void)volumeDidChangeWithVolumeUpdates:(NSArray<VolumeUpdate *> * _Nonnull)volumeUpdates;
/// Handles signal strength changes for attendees
/// Note: this callback will be called on main thread.
/// \param signalUpdates An array of SignalUpdates
///
- (void)signalStrengthDidChangeWithSignalUpdates:(NSArray<SignalUpdate *> * _Nonnull)signalUpdates;
/// List attendees that are newly added to the meeting
/// Note: this callback will be called on main thread.
/// \param attendeeInfo an array of AttendeeInfo added
///
- (void)attendeesDidJoinWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
/// List attendees that left the meeting
/// Note: this callback will be called on main thread.
/// \param attendeeInfo an array of AttendeeInfo who left
///
- (void)attendeesDidLeaveWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
/// List attendees that got dropped from the meeting due to network
/// Note: this callback will be called on main thread.
/// \param attendeeInfo an array of AttendeeInfo who are dropped
///
- (void)attendeesDidDropWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
/// List attendees that are newly muted in the meeting
/// Note: this callback will be called on main thread.
/// \param attendeeInfo an array of AttendeeInfo newly muted
///
- (void)attendeesDidMuteWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
/// List attendees that newly unmuted from the meeting
/// Note: this callback will be called on main thread.
/// \param attendeeInfo an array of AttendeeInfo newly unmuted
///
- (void)attendeesDidUnmuteWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK28DefaultActiveSpeakerDetector")
@interface DefaultActiveSpeakerDetector : NSObject <ActiveSpeakerDetectorFacade, RealtimeObserver>
- (nonnull instancetype)initWithSelfAttendeeId:(NSString * _Nonnull)selfAttendeeId OBJC_DESIGNATED_INITIALIZER;
- (void)hasBandwidthPriorityCallbackWithHasBandwidthPriority:(BOOL)hasBandwidthPriority;
- (void)volumeDidChangeWithVolumeUpdates:(NSArray<VolumeUpdate *> * _Nonnull)volumeUpdates;
- (void)signalStrengthDidChangeWithSignalUpdates:(NSArray<SignalUpdate *> * _Nonnull)signalUpdates;
- (void)attendeesDidLeaveWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
- (void)attendeesDidDropWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
- (void)attendeesDidMuteWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
- (void)attendeesDidUnmuteWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfo;
- (void)attendeesDidJoinWithAttendeeInfo:(NSArray<AttendeeInfo *> * _Nonnull)attendeeInfos;
- (void)addActiveSpeakerObserverWithPolicy:(id <ActiveSpeakerPolicy> _Nonnull)policy observer:(id <ActiveSpeakerObserver> _Nonnull)observer;
- (void)removeActiveSpeakerObserverWithObserver:(id <ActiveSpeakerObserver> _Nonnull)observer;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK26DefaultActiveSpeakerPolicy")
@interface DefaultActiveSpeakerPolicy : NSObject <ActiveSpeakerPolicy>
SWIFT_CLASS_PROPERTY(@property (nonatomic, class, readonly) double defaultSpeakerWeight;)
+ (double)defaultSpeakerWeight SWIFT_WARN_UNUSED_RESULT;
SWIFT_CLASS_PROPERTY(@property (nonatomic, class, readonly) double defaultCutoffThreshold;)
+ (double)defaultCutoffThreshold SWIFT_WARN_UNUSED_RESULT;
SWIFT_CLASS_PROPERTY(@property (nonatomic, class, readonly) double defaultTakeoverRate;)
+ (double)defaultTakeoverRate SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init;
- (nonnull instancetype)initWithSpeakerWeight:(double)speakerWeight cutoffThreshold:(double)cutoffThreshold takeoverRate:(double)takeoverRate OBJC_DESIGNATED_INITIALIZER;
- (double)calculateScoreWithAttendeeInfo:(AttendeeInfo * _Nonnull)attendeeInfo volume:(enum VolumeLevel)volume SWIFT_WARN_UNUSED_RESULT;
- (BOOL)prioritizeVideoSendBandwidthForActiveSpeaker SWIFT_WARN_UNUSED_RESULT;
@end

@protocol VideoClientController;
@protocol VideoTileController;

SWIFT_CLASS("_TtC14AmazonChimeSDK27DefaultAudioVideoController")
@interface DefaultAudioVideoController : NSObject <AudioVideoControllerFacade>
@property (nonatomic, readonly, strong) MeetingSessionConfiguration * _Nonnull configuration;
@property (nonatomic, readonly, strong) id <Logger> _Nonnull logger;
- (nonnull instancetype)initWithAudioClientController:(id <AudioClientController> _Nonnull)audioClientController audioClientObserver:(id <AudioClientObserver> _Nonnull)audioClientObserver clientMetricsCollector:(id <ClientMetricsCollector> _Nonnull)clientMetricsCollector videoClientController:(id <VideoClientController> _Nonnull)videoClientController videoTileController:(id <VideoTileController> _Nonnull)videoTileController configuration:(MeetingSessionConfiguration * _Nonnull)configuration logger:(id <Logger> _Nonnull)logger OBJC_DESIGNATED_INITIALIZER;
- (BOOL)startAndReturnError:(NSError * _Nullable * _Nullable)error;
- (BOOL)startWithCallKitEnabled:(BOOL)callKitEnabled error:(NSError * _Nullable * _Nullable)error;
- (BOOL)startWithAudioVideoConfiguration:(AudioVideoConfiguration * _Nonnull)audioVideoConfiguration error:(NSError * _Nullable * _Nullable)error;
- (void)stop;
- (void)addAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)removeAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)addMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
- (void)removeMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
- (BOOL)startLocalVideoAndReturnError:(NSError * _Nullable * _Nullable)error;
- (BOOL)startLocalVideoWithConfig:(LocalVideoConfiguration * _Nonnull)config error:(NSError * _Nullable * _Nullable)error;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopLocalVideo;
- (void)startRemoteVideo;
- (void)stopRemoteVideo;
- (void)updateVideoSourceSubscriptionsWithAddedOrUpdated:(NSDictionary<RemoteVideoSource *, VideoSubscriptionConfiguration *> * _Nonnull)addedOrUpdated removed:(NSArray<RemoteVideoSource *> * _Nonnull)removed;
- (void)promoteToPrimaryMeetingWithCredentials:(MeetingSessionCredentials * _Nonnull)credentials observer:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
- (void)demoteFromPrimaryMeeting;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@protocol EventAnalyticsController;
@protocol MeetingStatsCollector;

SWIFT_CLASS("_TtC14AmazonChimeSDK23DefaultAudioVideoFacade")
@interface DefaultAudioVideoFacade : NSObject <AudioVideoFacade>
@property (nonatomic, readonly, strong) MeetingSessionConfiguration * _Nonnull configuration;
@property (nonatomic, readonly, strong) id <Logger> _Nonnull logger;
- (nonnull instancetype)initWithAudioVideoController:(id <AudioVideoControllerFacade> _Nonnull)audioVideoController realtimeController:(id <RealtimeControllerFacade> _Nonnull)realtimeController deviceController:(id <DeviceController> _Nonnull)deviceController videoTileController:(id <VideoTileController> _Nonnull)videoTileController activeSpeakerDetector:(id <ActiveSpeakerDetectorFacade> _Nonnull)activeSpeakerDetector contentShareController:(id <ContentShareController> _Nonnull)contentShareController eventAnalyticsController:(id <EventAnalyticsController> _Nonnull)eventAnalyticsController meetingStatsCollector:(id <MeetingStatsCollector> _Nonnull)meetingStatsCollector OBJC_DESIGNATED_INITIALIZER;
- (BOOL)startWithAudioVideoConfiguration:(AudioVideoConfiguration * _Nonnull)audioVideoConfiguration error:(NSError * _Nullable * _Nullable)error;
- (BOOL)startWithCallKitEnabled:(BOOL)callKitEnabled error:(NSError * _Nullable * _Nullable)error;
- (BOOL)startAndReturnError:(NSError * _Nullable * _Nullable)error;
- (void)stop;
- (BOOL)startLocalVideoAndReturnError:(NSError * _Nullable * _Nullable)error;
- (BOOL)startLocalVideoWithConfig:(LocalVideoConfiguration * _Nonnull)config error:(NSError * _Nullable * _Nullable)error;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopLocalVideo;
- (void)startRemoteVideo;
- (void)stopRemoteVideo;
- (BOOL)realtimeLocalMute SWIFT_WARN_UNUSED_RESULT;
- (BOOL)realtimeLocalUnmute SWIFT_WARN_UNUSED_RESULT;
- (void)addRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)removeRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)addRealtimeDataMessageObserverWithTopic:(NSString * _Nonnull)topic observer:(id <DataMessageObserver> _Nonnull)observer;
- (void)removeRealtimeDataMessageObserverFromTopicWithTopic:(NSString * _Nonnull)topic;
- (BOOL)realtimeSendDataMessageWithTopic:(NSString * _Nonnull)topic data:(id _Nonnull)data lifetimeMs:(int32_t)lifetimeMs error:(NSError * _Nullable * _Nullable)error;
- (BOOL)realtimeSetVoiceFocusEnabledWithEnabled:(BOOL)enabled SWIFT_WARN_UNUSED_RESULT;
- (BOOL)realtimeIsVoiceFocusEnabled SWIFT_WARN_UNUSED_RESULT;
- (void)addAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)removeAudioVideoObserverWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)addMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
- (void)removeMetricsObserverWithObserver:(id <MetricsObserver> _Nonnull)observer;
- (void)addRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (void)removeRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (void)updateVideoSourceSubscriptionsWithAddedOrUpdated:(NSDictionary<RemoteVideoSource *, VideoSubscriptionConfiguration *> * _Nonnull)addedOrUpdated removed:(NSArray<RemoteVideoSource *> * _Nonnull)removed;
- (void)promoteToPrimaryMeetingWithCredentials:(MeetingSessionCredentials * _Nonnull)credentials observer:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
- (void)demoteFromPrimaryMeeting;
- (NSArray<MediaDevice *> * _Nonnull)listAudioDevices SWIFT_WARN_UNUSED_RESULT;
- (void)chooseAudioDeviceWithMediaDevice:(MediaDevice * _Nonnull)mediaDevice;
- (void)addDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
- (void)removeDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
- (void)switchCamera;
- (MediaDevice * _Nullable)getActiveCamera SWIFT_WARN_UNUSED_RESULT;
- (MediaDevice * _Nullable)getActiveAudioDevice SWIFT_WARN_UNUSED_RESULT;
- (void)bindVideoViewWithVideoView:(id <VideoRenderView> _Nonnull)videoView tileId:(NSInteger)tileId;
- (void)unbindVideoViewWithTileId:(NSInteger)tileId;
- (void)addVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
- (void)removeVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
- (void)pauseRemoteVideoTileWithTileId:(NSInteger)tileId;
- (void)resumeRemoteVideoTileWithTileId:(NSInteger)tileId;
- (void)addActiveSpeakerObserverWithPolicy:(id <ActiveSpeakerPolicy> _Nonnull)policy observer:(id <ActiveSpeakerObserver> _Nonnull)observer;
- (void)removeActiveSpeakerObserverWithObserver:(id <ActiveSpeakerObserver> _Nonnull)observer;
- (void)hasBandwidthPriorityCallbackWithHasBandwidthPriority:(BOOL)hasBandwidthPriority;
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source;
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopContentShare;
- (void)addContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (void)removeContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (void)addEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
- (void)removeEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
- (NSDictionary * _Nonnull)getCommonEventAttributes SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK26DefaultCameraCaptureSource")
@interface DefaultCameraCaptureSource : NSObject <CameraCaptureSource>
@property (nonatomic) enum VideoContentHint videoContentHint;
- (nonnull instancetype)initWithLogger:(id <Logger> _Nonnull)logger OBJC_DESIGNATED_INITIALIZER;
@property (nonatomic, strong) MediaDevice * _Nullable device;
@property (nonatomic, strong) VideoCaptureFormat * _Nonnull format;
@property (nonatomic) BOOL torchEnabled;
/// Expose current capture device’s torch availability
@property (nonatomic, readonly) BOOL torchAvailable;
- (void)addVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
- (void)removeVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
- (void)start;
- (void)stop;
- (void)switchCamera;
- (void)addCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
- (void)removeCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
- (void)setEventAnalyticsControllerWithEventAnalyticsController:(id <EventAnalyticsController> _Nullable)eventAnalyticsController;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class AVCaptureOutput;
@class AVCaptureConnection;

@interface DefaultCameraCaptureSource (SWIFT_EXTENSION(AmazonChimeSDK)) <AVCaptureVideoDataOutputSampleBufferDelegate>
- (void)captureOutput:(AVCaptureOutput * _Nonnull)_ didOutputSampleBuffer:(CMSampleBufferRef _Nonnull)sampleBuffer fromConnection:(AVCaptureConnection * _Nonnull)_;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK29DefaultContentShareController")
@interface DefaultContentShareController : NSObject <ContentShareController>
- (nonnull instancetype)initWithContentShareVideoClientController:(id <ContentShareVideoClientController> _Nonnull)contentShareVideoClientController OBJC_DESIGNATED_INITIALIZER;
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source;
- (void)startContentShareWithSource:(ContentShareSource * _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopContentShare;
- (void)addContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (void)removeContentShareObserverWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@protocol VideoClientProtocol;

SWIFT_CLASS("_TtC14AmazonChimeSDK40DefaultContentShareVideoClientController")
@interface DefaultContentShareVideoClientController : NSObject <ContentShareVideoClientController>
- (nonnull instancetype)initWithVideoClient:(id <VideoClientProtocol> _Nonnull)videoClient configuration:(MeetingSessionConfiguration * _Nonnull)configuration logger:(id <Logger> _Nonnull)logger clientMetricsCollector:(id <ClientMetricsCollector> _Nonnull)clientMetricsCollector OBJC_DESIGNATED_INITIALIZER;
- (void)startVideoShareWithSource:(id <VideoSource> _Nonnull)source;
- (void)startVideoShareWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopVideoShare;
- (void)subscribeToVideoClientStateChangeWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (void)unsubscribeFromVideoClientStateChangeWithObserver:(id <ContentShareObserver> _Nonnull)observer;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class VideoClient;

@interface DefaultContentShareVideoClientController (SWIFT_EXTENSION(AmazonChimeSDK)) <VideoClientDelegate>
- (void)videoClientRequestTurnCreds:(VideoClient * _Nullable)client;
- (void)videoClientIsConnecting:(VideoClient * _Nullable)client;
- (void)videoClientDidConnect:(VideoClient * _Nullable)client controlStatus:(int32_t)controlStatus;
- (void)videoClientDidFail:(VideoClient * _Nullable)client status:(video_client_status_t)status controlStatus:(int32_t)controlStatus;
- (void)videoClientDidStop:(VideoClient * _Nullable)client;
- (void)videoClientMetricsReceived:(NSDictionary * _Nullable)metrics;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK23DefaultDeviceController")
@interface DefaultDeviceController : NSObject <DeviceController>
- (nonnull instancetype)initWithAudioSession:(id <AudioSession> _Nonnull)audioSession videoClientController:(id <VideoClientController> _Nonnull)videoClientController eventAnalyticsController:(id <EventAnalyticsController> _Nonnull)eventAnalyticsController logger:(id <Logger> _Nonnull)logger OBJC_DESIGNATED_INITIALIZER;
- (NSArray<MediaDevice *> * _Nonnull)listAudioDevices SWIFT_WARN_UNUSED_RESULT;
- (void)chooseAudioDeviceWithMediaDevice:(MediaDevice * _Nonnull)mediaDevice;
- (void)addDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
- (void)removeDeviceChangeObserverWithObserver:(id <DeviceChangeObserver> _Nonnull)observer;
- (void)switchCamera;
- (MediaDevice * _Nullable)getActiveCamera SWIFT_WARN_UNUSED_RESULT;
- (MediaDevice * _Nullable)getActiveAudioDevice SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

enum EventName : NSInteger;
enum MeetingHistoryEventName : NSInteger;

/// <code>EventAnalyticsController</code> keeps track of events and notifies <code>EventAnalyticsObserver</code>.
/// An event describes the success and failure conditions for the meeting session.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK24EventAnalyticsController_")
@protocol EventAnalyticsController
- (void)publishEventWithName:(enum EventName)name;
/// Publish an event with updated <code>EventAttributes</code>
/// \param name Name of event to publish
///
/// \param attributes Attributes <code>EventAttributes</code> for that meeting event
///
- (void)publishEventWithName:(enum EventName)name attributes:(NSDictionary * _Nonnull)attributes;
/// Push <code>MeetingHistoryEventName</code> to internal <code>MeetingStatsCollector</code> states to later pass to builders
/// \param historyEventName History state to put in the meeting history
///
- (void)pushHistoryWithHistoryEventName:(enum MeetingHistoryEventName)historyEventName;
/// Subscribes to meeting event related data with an observer
/// \param observer An observer to add to start receiving meeting events
///
- (void)addEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
/// Unsubscribes from meeting event by removing the specified observer
/// \param observer An observer to remove to stop receiving meeting events
///
- (void)removeEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
/// Retrieve meeting history.
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
/// Retrieve common attributes, including deviceName, osName, and more.
- (NSDictionary * _Nonnull)getCommonEventAttributes SWIFT_WARN_UNUSED_RESULT;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK31DefaultEventAnalyticsController")
@interface DefaultEventAnalyticsController : NSObject <EventAnalyticsController>
- (void)publishEventWithName:(enum EventName)name attributes:(NSDictionary * _Nonnull)attributes;
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
- (void)publishEventWithName:(enum EventName)name;
- (void)pushHistoryWithHistoryEventName:(enum MeetingHistoryEventName)historyEventName;
- (void)addEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
- (void)removeEventAnalyticsObserverWithObserver:(id <EventAnalyticsObserver> _Nonnull)observer;
- (NSDictionary * _Nonnull)getCommonEventAttributes SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class SDKEvent;

/// <code>EventReporter</code> process data. It will be called in <code>DefaultEventAnalyticsController</code>.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK13EventReporter_")
@protocol EventReporter
/// Process the event. For instance, in the default implementation, it will save it to Event Table.
/// \param event SDK related events
///
- (void)reportWithEvent:(SDKEvent * _Nonnull)event;
/// Start the EventReporter
- (void)start;
/// Stop the EventReporter
- (void)stop;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK20DefaultEventReporter")
@interface DefaultEventReporter : NSObject <EventReporter>
- (void)reportWithEvent:(SDKEvent * _Nonnull)event;
- (void)start;
- (void)stop;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_PROTOCOL("_TtP14AmazonChimeSDK14MeetingSession_")
@protocol MeetingSession
@property (nonatomic, readonly, strong) MeetingSessionConfiguration * _Nonnull configuration;
@property (nonatomic, readonly, strong) id <Logger> _Nonnull logger;
@property (nonatomic, readonly, strong) id <AudioVideoFacade> _Nonnull audioVideo;
@property (nonatomic, readonly, strong) id <EventAnalyticsController> _Nonnull eventAnalyticsController;
@end

@protocol EventReporterFactory;

SWIFT_CLASS("_TtC14AmazonChimeSDK21DefaultMeetingSession")
@interface DefaultMeetingSession : NSObject <MeetingSession>
@property (nonatomic, readonly, strong) id <AudioVideoFacade> _Nonnull audioVideo;
@property (nonatomic, readonly, strong) MeetingSessionConfiguration * _Nonnull configuration;
@property (nonatomic, readonly, strong) id <Logger> _Nonnull logger;
@property (nonatomic, readonly, strong) id <EventAnalyticsController> _Nonnull eventAnalyticsController;
- (nonnull instancetype)initWithConfiguration:(MeetingSessionConfiguration * _Nonnull)configuration logger:(id <Logger> _Nonnull)logger eventReporterFactory:(id <EventReporterFactory> _Nonnull)eventReporterFactory OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)initWithConfiguration:(MeetingSessionConfiguration * _Nonnull)configuration logger:(id <Logger> _Nonnull)logger;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_PROTOCOL("_TtP14AmazonChimeSDK21MeetingStatsCollector_")
@protocol MeetingStatsCollector
/// Increment meeting session retry count.
- (void)incrementRetryCount;
/// Increment poor connection count during the meeting session based on audio quality.
- (void)incrementPoorConnectionCount;
/// Add meeting history event.
- (void)addMeetingHistoryEventWithHistoryEventName:(enum MeetingHistoryEventName)historyEventName timestampMs:(int64_t)timestampMs;
/// Update max video tile count during the meeting.
/// \param videoTileCount current video tile count
///
- (void)updateMaxVideoTileWithVideoTileCount:(NSInteger)videoTileCount;
/// Update meetingStartConnectingTimeMs.
- (void)updateMeetingStartConnectingTimeMs;
/// Update meetingStartTimeMs.
- (void)updateMeetingStartTimeMs;
/// Clear internal states of <code>MeetingStatsCollector</code>.
- (void)resetMeetingStats;
/// Retrieve meeting stats.
- (NSDictionary * _Nonnull)getMeetingStats SWIFT_WARN_UNUSED_RESULT;
/// Retrieve meeting history.
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK28DefaultMeetingStatsCollector")
@interface DefaultMeetingStatsCollector : NSObject <MeetingStatsCollector>
- (NSArray<MeetingHistoryEvent *> * _Nonnull)getMeetingHistory SWIFT_WARN_UNUSED_RESULT;
- (NSDictionary * _Nonnull)getMeetingStats SWIFT_WARN_UNUSED_RESULT;
- (void)addMeetingHistoryEventWithHistoryEventName:(enum MeetingHistoryEventName)historyEventName timestampMs:(int64_t)timestampMs;
- (void)incrementRetryCount;
- (void)incrementPoorConnectionCount;
- (void)updateMaxVideoTileWithVideoTileCount:(NSInteger)videoTileCount;
- (void)updateMeetingStartConnectingTimeMs;
- (void)updateMeetingStartTimeMs;
- (void)resetMeetingStats;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

enum ModalityType : NSInteger;

/// <code>DefaultModality</code> is a backwards compatible extension of the
/// attendee id (UUID string) and session token schemas (base 64 string).
/// It appends #<modality> to either string, which indicates the modality
/// of the participant.
/// For example,
/// <code>attendeeId</code>: “abcdefg”
/// <code>contentAttendeeId</code>: “abcdefg#content”
/// <code>DefaultModality(id: contentAttendeeId).base</code>: “abcdefg”
/// <code>DefaultModality(id: contentAttendeeId).modality</code>: “content”
/// <code>DefaultModality(id: contentAttendeeId).isOfType(type: .content)</code>: true
SWIFT_CLASS("_TtC14AmazonChimeSDK15DefaultModality")
@interface DefaultModality : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull id;
@property (nonatomic, readonly, copy) NSString * _Nonnull base;
@property (nonatomic, readonly, copy) NSString * _Nullable modality;
- (nonnull instancetype)initWithId:(NSString * _Nonnull)id OBJC_DESIGNATED_INITIALIZER;
- (BOOL)isOfTypeWithType:(enum ModalityType)type SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK25DefaultRealtimeController")
@interface DefaultRealtimeController : NSObject <RealtimeControllerFacade>
- (nonnull instancetype)initWithAudioClientController:(id <AudioClientController> _Nonnull)audioClientController audioClientObserver:(id <AudioClientObserver> _Nonnull)audioClientObserver videoClientController:(id <VideoClientController> _Nonnull)videoClientController OBJC_DESIGNATED_INITIALIZER;
- (BOOL)realtimeLocalMute SWIFT_WARN_UNUSED_RESULT;
- (BOOL)realtimeLocalUnmute SWIFT_WARN_UNUSED_RESULT;
- (void)addRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)removeRealtimeObserverWithObserver:(id <RealtimeObserver> _Nonnull)observer;
- (void)addRealtimeDataMessageObserverWithTopic:(NSString * _Nonnull)topic observer:(id <DataMessageObserver> _Nonnull)observer;
- (void)removeRealtimeDataMessageObserverFromTopicWithTopic:(NSString * _Nonnull)topic;
- (BOOL)realtimeSendDataMessageWithTopic:(NSString * _Nonnull)topic data:(id _Nonnull)data lifetimeMs:(int32_t)lifetimeMs error:(NSError * _Nullable * _Nullable)error;
- (BOOL)realtimeSetVoiceFocusEnabledWithEnabled:(BOOL)enabled SWIFT_WARN_UNUSED_RESULT;
- (BOOL)realtimeIsVoiceFocusEnabled SWIFT_WARN_UNUSED_RESULT;
- (void)addRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (void)removeRealtimeTranscriptEventObserverWithObserver:(id <TranscriptEventObserver> _Nonnull)observer;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class VideoFrame;

/// A <code>VideoSink</code> consumes video frames, typically from a <code>VideoSource</code>. It may process, fork, or render these frames.
/// Typically connected via video <code>VideoSource.addVideoSink</code> and disconnected via <code>VideoSource.removeVideoSink</code>
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK9VideoSink_")
@protocol VideoSink
/// Receive a video frame from some upstream source.
/// The <code>VideoSink</code> may render, store, process, and forward the frame, among other applications.
/// \param frame New video frame to consume
///
- (void)onVideoFrameReceivedWithFrame:(VideoFrame * _Nonnull)frame;
@end


/// <code>VideoRenderView</code> is the type of VideoSink used by the <code>VideoTileController</code>
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK15VideoRenderView_")
@protocol VideoRenderView <VideoSink>
@end

@class NSCoder;
@class UIImage;

SWIFT_CLASS("_TtC14AmazonChimeSDK22DefaultVideoRenderView")
@interface DefaultVideoRenderView : UIImageView <VideoRenderView>
@property (nonatomic) BOOL mirror;
@property (nonatomic) UIViewContentMode contentMode;
- (nullable instancetype)initWithCoder:(NSCoder * _Nonnull)coder OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)initWithFrame:(CGRect)frame OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init;
- (void)onVideoFrameReceivedWithFrame:(VideoFrame * _Nonnull)frame;
- (void)resetImage;
- (nonnull instancetype)initWithImage:(UIImage * _Nullable)image SWIFT_UNAVAILABLE;
- (nonnull instancetype)initWithImage:(UIImage * _Nullable)image highlightedImage:(UIImage * _Nullable)highlightedImage SWIFT_UNAVAILABLE;
@end

@class VideoTileState;
enum VideoPauseState : NSInteger;

/// <code>VideoTile</code> is a tile that binds video render view to diplay the frame into the view.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK9VideoTile_")
@protocol VideoTile <VideoSink>
/// State of VideoTile
@property (nonatomic, readonly, strong) VideoTileState * _Nonnull state;
/// View which will be used to render the Video Frame
@property (nonatomic, strong) id <VideoRenderView> _Nullable videoRenderView;
/// Binds the view to the tile. The view needs to be create by the application.
/// Once the binding is done, the view will start displaying the video frame automatically
/// \param videoRenderView the view created by application to render the video frame
///
- (void)bindWithVideoRenderView:(id <VideoRenderView> _Nullable)videoRenderView;
/// Unbinds the <code>videoRenderView</code> from tile.
- (void)unbind;
/// Update the pause state of the tile.
- (void)setPauseStateWithPauseState:(enum VideoPauseState)pauseState;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK16DefaultVideoTile")
@interface DefaultVideoTile : NSObject <VideoTile>
@property (nonatomic, strong) VideoTileState * _Nonnull state;
@property (nonatomic, strong) id <VideoRenderView> _Nullable videoRenderView;
- (nonnull instancetype)initWithTileId:(NSInteger)tileId attendeeId:(NSString * _Nonnull)attendeeId videoStreamContentWidth:(NSInteger)videoStreamContentWidth videoStreamContentHeight:(NSInteger)videoStreamContentHeight isLocalTile:(BOOL)isLocalTile logger:(id <Logger> _Nonnull)logger OBJC_DESIGNATED_INITIALIZER;
- (void)bindWithVideoRenderView:(id <VideoRenderView> _Nullable)videoRenderView;
- (void)onVideoFrameReceivedWithFrame:(VideoFrame * _Nonnull)frame;
- (void)unbind;
- (void)setPauseStateWithPauseState:(enum VideoPauseState)pauseState;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>VideoTileController</code> handles rendering/creating of new <code>VideoTile</code>.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19VideoTileController_")
@protocol VideoTileController <VideoTileControllerFacade>
/// Called whenever there is a new Video frame received for any of the attendee in the meeting
/// \param frame a frame of video
///
/// \param videoId unique id that belongs to video being transmitted
///
/// \param attendeeId a id of user who is transmitting current frame
///
/// \param pauseState current pause state of the video being received
///
- (void)onReceiveFrameWithFrame:(VideoFrame * _Nullable)frame videoId:(NSInteger)videoId attendeeId:(NSString * _Nullable)attendeeId pauseState:(enum VideoPauseState)pauseState;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK26DefaultVideoTileController")
@interface DefaultVideoTileController : NSObject <VideoTileController>
- (nonnull instancetype)initWithVideoClientController:(id <VideoClientController> _Nonnull)videoClientController logger:(id <Logger> _Nonnull)logger meetingStatsCollector:(id <MeetingStatsCollector> _Nonnull)meetingStatsCollector OBJC_DESIGNATED_INITIALIZER;
- (void)onReceiveFrameWithFrame:(VideoFrame * _Nullable)frame videoId:(NSInteger)videoId attendeeId:(NSString * _Nullable)attendeeId pauseState:(enum VideoPauseState)pauseState;
- (void)bindVideoViewWithVideoView:(id <VideoRenderView> _Nonnull)videoView tileId:(NSInteger)tileId;
- (void)unbindVideoViewWithTileId:(NSInteger)tileId;
- (void)addVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
- (void)removeVideoTileObserverWithObserver:(id <VideoTileObserver> _Nonnull)observer;
- (void)pauseRemoteVideoTileWithTileId:(NSInteger)tileId;
- (void)resumeRemoteVideoTileWithTileId:(NSInteger)tileId;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>DeviceChangeObserver</code> listens to the change of Audio Device.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK20DeviceChangeObserver_")
@protocol DeviceChangeObserver
/// Called when listAudioDevices() output changed
/// In another word, when a new media device become available
/// or old media device become unavailable
/// Note: this callback will be called on main thread.
/// \param freshAudioDeviceList updated list of available devices
///
- (void)audioDeviceDidChangeWithFreshAudioDeviceList:(NSArray<MediaDevice *> * _Nonnull)freshAudioDeviceList;
@end



SWIFT_CLASS("_TtC14AmazonChimeSDK11DeviceUtils")
@interface DeviceUtils : NSObject
+ (NSString * _Nonnull)getModelInfo SWIFT_WARN_UNUSED_RESULT;
+ (app_detailed_info_t)getDetailedInfo SWIFT_WARN_UNUSED_RESULT;
+ (AppInfo * _Nonnull)getAppInfo SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end




/// <code>EventAnalyticsObserver</code> handles events regarding to analytics.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK22EventAnalyticsObserver_")
@protocol EventAnalyticsObserver
/// Called when specific events occur during the meeting and includes attributes of the event.
/// This can be used to create analytics around meeting metric.
/// \param name name of the event
///
/// \param attributes attributes of the event
///
- (void)eventDidReceiveWithName:(enum EventName)name attributes:(NSDictionary * _Nonnull)attributes;
@end

/// EventAttributeName describes key of attributes that are passed in <code>EventAnalyticsObserver.eventDidReceive</code>
typedef SWIFT_ENUM(NSInteger, EventAttributeName, open) {
/// Name of device = Manufacturer of Device + Device Model
  EventAttributeNameDeviceName = 0,
/// Manufacturer of Device
  EventAttributeNameDeviceManufacturer = 1,
/// Model of Device
  EventAttributeNameDeviceModel = 2,
/// Operating system name, which is “iOS”
  EventAttributeNameOsName = 3,
/// Operating system version
  EventAttributeNameOsVersion = 4,
/// Name of SDK, which is “amazon-chime-sdk-ios”
  EventAttributeNameSdkName = 5,
/// Version of SDK
  EventAttributeNameSdkVersion = 6,
/// Version of media SDK
  EventAttributeNameMediaSdkVersion = 7,
/// Timestamp of event occurrence
  EventAttributeNameTimestampMs = 8,
/// AttendeeId
  EventAttributeNameAttendeeId = 9,
/// External Meeting Id
  EventAttributeNameExternalMeetingId = 10,
/// External Attendee Id
  EventAttributeNameExternalUserId = 11,
/// Meeting Id
  EventAttributeNameMeetingId = 12,
/// History of the meeting events in chronological order
  EventAttributeNameMeetingHistory = 13,
/// Maximum number video tile shared during the meeting, including self video tile
  EventAttributeNameMaxVideoTileCount = 14,
/// Duration of the meeting start process
  EventAttributeNameMeetingStartDurationMs = 15,
/// Duration of the meeting
  EventAttributeNameMeetingDurationMs = 16,
/// Error message of the meeting
  EventAttributeNameMeetingErrorMessage = 17,
/// Meeting Status <code>MeetingSessionStatus</code>
  EventAttributeNameMeetingStatus = 18,
/// The number of poor connection count during the meeting from start to end
  EventAttributeNamePoorConnectionCount = 19,
/// The number of meeting retry connection count during the meeting from start to end
  EventAttributeNameRetryCount = 20,
/// The error of video input selection such as starting camera
  EventAttributeNameVideoInputError = 21,
};


/// <code>EventBuffer</code> defines storing and consuming of event data.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK11EventBuffer_")
@protocol EventBuffer
/// Add an item.
/// \param item item to add
///
- (void)addWithItem:(SDKEvent * _Nonnull)item;
/// Process the data in the buffer
- (void)process;
@end

enum EventClientType : NSInteger;

/// <code>EventClientConfiguration</code> contains speciic data required to send as metadata.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK24EventClientConfiguration_")
@protocol EventClientConfiguration
/// The type of the Ingestion event
/// attention:
/// replaced with <code>tag</code>
@property (nonatomic, readonly) enum EventClientType type;
@property (nonatomic, readonly, copy) NSString * _Nonnull eventClientJoinToken;
/// Tagging the source of the events, which will be translated to <code>Type</code> for Ingestion event
@property (nonatomic, readonly, copy) NSString * _Nonnull tag;
/// The attributes that will be sent to Ingestion Service as metadata along with common attributes
@property (nonatomic, readonly, copy) NSDictionary<NSString *, id> * _Nonnull metadataAttributes;
@end

/// <code>EventClientType</code> defines type of <code>EventClientConfiguration</code>
typedef SWIFT_ENUM(NSInteger, EventClientType, open) {
  EventClientTypeMeet = 0,
  EventClientTypeChat = 1,
};

/// <code>EventName</code> represent some major event that could help builders to analyze the data
typedef SWIFT_ENUM(NSInteger, EventName, open) {
/// The camera selection failed.
  EventNameVideoInputFailed = 0,
/// The meeting will start.
  EventNameMeetingStartRequested = 1,
/// The meeting started.
  EventNameMeetingStartSucceeded = 2,
/// The meeting failed to start.
  EventNameMeetingStartFailed = 3,
/// The meeting ended with failure
  EventNameMeetingFailed = 4,
/// The meeting ended.
  EventNameMeetingEnded = 5,
  EventNameUnknown = 6,
};



SWIFT_PROTOCOL("_TtP14AmazonChimeSDK20EventReporterFactory_")
@protocol EventReporterFactory
- (id <EventReporter> _Nullable)createEventReporter SWIFT_WARN_UNUSED_RESULT;
@end

@class IngestionRecord;

/// <code>EventSender</code> handles the sending of ingestion record
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK11EventSender_")
@protocol EventSender
/// Send events as <code>IngestionRecord</code>
/// \param ingestionRecord ingestion record
///
/// \param completionHandler complete handler to execute when send event succeeded or failed
///
- (void)sendEventsWithIngestionRecord:(IngestionRecord * _Nonnull)ingestionRecord completionHandler:(void (^ _Nonnull)(BOOL))completionHandler;
@end


/// <code>InAppScreenCaptureSource</code> is used to share screen capture within the app. When the app is in the background,
/// there is no sample sent to handler, and screen sharing is paused. <code>InAppScreenCaptureSource</code> is only available
/// on iOS 11+ because of <code>RPScreenRecorder.startCapture(handler:completionHandler:)</code> method.
/// <code>InAppScreenCaptureSource</code> does not support rotation while it’s in progress.
SWIFT_CLASS("_TtC14AmazonChimeSDK24InAppScreenCaptureSource") SWIFT_AVAILABILITY(ios,introduced=11.0)
@interface InAppScreenCaptureSource : NSObject <VideoCaptureSource>
@property (nonatomic) enum VideoContentHint videoContentHint;
- (nonnull instancetype)initWithLogger:(id <Logger> _Nonnull)logger OBJC_DESIGNATED_INITIALIZER;
- (void)start;
- (void)stop;
- (void)addVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
- (void)removeVideoSinkWithSink:(id <VideoSink> _Nonnull)sink;
- (void)addCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
- (void)removeCaptureSourceObserverWithObserver:(id <CaptureSourceObserver> _Nonnull)observer;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>IngestionConfiguration</code> defines the configuration needed for ingestion service.
/// This will be passed down to <code>DefaultEventReporter</code>
SWIFT_CLASS("_TtC14AmazonChimeSDK22IngestionConfiguration")
@interface IngestionConfiguration : NSObject
/// Event client configuration specific that has different properties based on type.
/// For instance, meeting client configuration should have meetingId and attendeeId.
@property (nonatomic, readonly, strong) id <EventClientConfiguration> _Nonnull clientConfiguration;
/// Url of ingestion endpoint to send data.
@property (nonatomic, readonly, copy) NSString * _Nonnull ingestionUrl;
/// Whether ingestion is enabled or disabled.
@property (nonatomic, readonly) BOOL disabled;
/// Size to send to the server in a batch.
/// Constraints:  >= 1 and <=100.
@property (nonatomic, readonly) NSInteger flushSize;
/// Interval to continously send to the server in a batch.
/// Constraints: >= 300 ms.
@property (nonatomic, readonly) int64_t flushIntervalMs;
/// Number of retries.
/// Constraints:  >= 1 and <= 3.
@property (nonatomic, readonly) NSInteger retryCountLimit;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>IngestionConfigurationBuilder</code> helps to create <code>IngestionConfiguration</code>
/// by providing builder pattern.
SWIFT_CLASS("_TtC14AmazonChimeSDK29IngestionConfigurationBuilder")
@interface IngestionConfigurationBuilder : NSObject
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
- (IngestionConfigurationBuilder * _Nonnull)setFlushSizeWithFlushSize:(NSInteger)flushSize SWIFT_WARN_UNUSED_RESULT;
- (IngestionConfigurationBuilder * _Nonnull)setFlushIntervalMsWithFlushIntervalMs:(int64_t)flushIntervalMs SWIFT_WARN_UNUSED_RESULT;
- (IngestionConfigurationBuilder * _Nonnull)setRetryCountLimitWithRetryCountLimit:(NSInteger)retryCountLimit SWIFT_WARN_UNUSED_RESULT;
- (IngestionConfiguration * _Nonnull)buildWithDisabled:(BOOL)disabled ingestionUrl:(NSString * _Nonnull)ingestionUrl clientConiguration:(id <EventClientConfiguration> _Nonnull)clientConiguration SWIFT_WARN_UNUSED_RESULT;
@end

@class IngestionPayload;

/// Event data that will be send to the ingestion server
SWIFT_CLASS("_TtC14AmazonChimeSDK14IngestionEvent")
@interface IngestionEvent : NSObject
/// Event Client Type associated with this event
@property (nonatomic, readonly, copy) NSString * _Nonnull type;
/// Payload associated with this ingestion event.
@property (nonatomic, readonly, copy) NSArray<IngestionPayload *> * _Nonnull payloads;
/// Version of payload. Different event format could give different version.
@property (nonatomic, readonly) NSInteger version;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>IngestionEventConverter</code> converts data from payload into <code>MeetingEventItem</code>/<code>DirtyEventItem</code>or vice versa.
SWIFT_CLASS("_TtC14AmazonChimeSDK23IngestionEventConverter")
@interface IngestionEventConverter : NSObject
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK16IngestionPayload")
@interface IngestionPayload : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull name;
@property (nonatomic, readonly) int64_t ts;
@property (nonatomic, readonly, copy) NSString * _Nullable id;
@property (nonatomic, readonly, copy) NSString * _Nullable meetingErrorMessage;
@property (nonatomic, readonly, copy) NSString * _Nullable meetingStatus;
@property (nonatomic, readonly, copy) NSString * _Nullable videoInputErrorMessage;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>IngestionRecord</code> is the format of data that will be consumed on the ingestion server.
SWIFT_CLASS("_TtC14AmazonChimeSDK15IngestionRecord")
@interface IngestionRecord : NSObject
/// List of <code>IngestionEvent</code>
@property (nonatomic, readonly, copy) NSArray<IngestionEvent *> * _Nonnull events;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>Scheduler</code> calls a callback on the schedule determined by the implementation.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK9Scheduler_")
@protocol Scheduler
/// Schedules the callback according to the implementation.
- (void)start;
/// Unschedules the callback and prevents it from being called anymore.
- (void)stop;
@end


/// <code>IntervalScheduler</code> calls the callback every intervalMs milliseconds.
SWIFT_CLASS("_TtC14AmazonChimeSDK17IntervalScheduler")
@interface IntervalScheduler : NSObject <Scheduler>
- (nonnull instancetype)initWithIntervalMs:(NSInteger)intervalMs callback:(void (^ _Nonnull)(void))callback OBJC_DESIGNATED_INITIALIZER;
- (void)start;
- (void)stop;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// Configuration for a local video or content share to be sent
SWIFT_CLASS("_TtC14AmazonChimeSDK23LocalVideoConfiguration")
@interface LocalVideoConfiguration : NSObject
/// The flag to disable/enable simulcast, default to true
/// For local video use only, will not work for content share
@property (nonatomic) BOOL simulcastEnabled;
/// The max bit rate for video encoding, should be greater than 0
/// Actual quality achieved may vary throughout the call depending on what system and network can provide
@property (nonatomic) uint32_t maxBitRateKbps;
- (nonnull instancetype)initWithMaxBitRateKbps:(uint32_t)maxBitRateKbps simulcastEnabled:(BOOL)simulcastEnabled OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

typedef SWIFT_ENUM(NSInteger, LogLevel, open) {
  LogLevelDEFAULT = 0,
  LogLevelDEBUG = 1,
  LogLevelINFO = 2,
  LogLevelFAULT = 3,
  LogLevelERROR = 4,
  LogLevelOFF = 5,
};


enum MediaDeviceType : NSInteger;

/// <code>MediaDevice</code> represents an IOS audio/video device.
SWIFT_CLASS("_TtC14AmazonChimeSDK11MediaDevice")
@interface MediaDevice : NSObject
/// Label of MediaDevice
@property (nonatomic, readonly, copy) NSString * _Nonnull label;
/// Type of MediaDevice (ex: Bluetooth Audio, Front Camera)
@property (nonatomic, readonly) enum MediaDeviceType type;
/// Audio Information based on iOS native <code>AVAudioSessionPortDescription</code>
/// It will be null when it represent a video device.
@property (nonatomic, readonly, strong) AVAudioSessionPortDescription * _Nullable port;
/// List available video capture devices from the hardware
+ (NSArray<MediaDevice *> * _Nonnull)listVideoDevices SWIFT_WARN_UNUSED_RESULT;
/// List available <code>VideoCaptureFormat</code> from the video capture device.
/// This methods returns an empty array for <code>MediaDevice</code> that’s not used for video.
/// \param mediaDevice Video capture device to query
///
+ (NSArray<VideoCaptureFormat *> * _Nonnull)listSupportedVideoCaptureFormatsWithMediaDevice:(MediaDevice * _Nonnull)mediaDevice SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)initWithLabel:(NSString * _Nonnull)label type:(enum MediaDeviceType)type OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)initWithLabel:(NSString * _Nonnull)label port:(AVAudioSessionPortDescription * _Nullable)port OBJC_DESIGNATED_INITIALIZER;
@property (nonatomic, readonly, copy) NSString * _Nonnull description;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

typedef SWIFT_ENUM(NSInteger, MediaDeviceType, open) {
  MediaDeviceTypeAudioBluetooth = 0,
  MediaDeviceTypeAudioWiredHeadset = 1,
  MediaDeviceTypeAudioBuiltInSpeaker = 2,
  MediaDeviceTypeAudioHandset = 3,
  MediaDeviceTypeVideoFrontCamera = 4,
  MediaDeviceTypeVideoBackCamera = 5,
  MediaDeviceTypeOther = 6,
};

typedef SWIFT_ENUM(NSInteger, MediaError, open) {
  MediaErrorIllegalState = 0,
  MediaErrorAudioFailedToStart = 1,
};
static NSString * _Nonnull const MediaErrorDomain = @"AmazonChimeSDK.MediaError";


SWIFT_CLASS("_TtC14AmazonChimeSDK14MediaPlacement")
@interface MediaPlacement : NSObject
- (nonnull instancetype)initWithAudioFallbackUrl:(NSString * _Nonnull)audioFallbackUrl audioHostUrl:(NSString * _Nonnull)audioHostUrl signalingUrl:(NSString * _Nonnull)signalingUrl turnControlUrl:(NSString * _Nonnull)turnControlUrl;
- (nonnull instancetype)initWithAudioFallbackUrl:(NSString * _Nonnull)audioFallbackUrl audioHostUrl:(NSString * _Nonnull)audioHostUrl signalingUrl:(NSString * _Nonnull)signalingUrl turnControlUrl:(NSString * _Nonnull)turnControlUrl eventIngestionUrl:(NSString * _Nullable)eventIngestionUrl OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK7Meeting")
@interface Meeting : NSObject
- (nonnull instancetype)initWithExternalMeetingId:(NSString * _Nullable)externalMeetingId mediaPlacement:(MediaPlacement * _Nonnull)mediaPlacement mediaRegion:(NSString * _Nonnull)mediaRegion meetingId:(NSString * _Nonnull)meetingId;
- (nonnull instancetype)initWithExternalMeetingId:(NSString * _Nullable)externalMeetingId mediaPlacement:(MediaPlacement * _Nonnull)mediaPlacement mediaRegion:(NSString * _Nonnull)mediaRegion meetingId:(NSString * _Nonnull)meetingId primaryMeetingId:(NSString * _Nullable)primaryMeetingId OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>MeetingEventClientConfiguration</code> is one type of <code>EventClientConfiguration</code> that contains
/// information about the meeting
SWIFT_CLASS("_TtC14AmazonChimeSDK31MeetingEventClientConfiguration")
@interface MeetingEventClientConfiguration : NSObject <EventClientConfiguration>
@property (nonatomic, readonly) enum EventClientType type;
@property (nonatomic, readonly, copy) NSString * _Nonnull eventClientJoinToken;
@property (nonatomic, copy) NSString * _Nonnull tag;
@property (nonatomic, copy) NSDictionary<NSString *, id> * _Nonnull metadataAttributes;
- (nonnull instancetype)initWithEventClientJoinToken:(NSString * _Nonnull)eventClientJoinToken meetingId:(NSString * _Nonnull)meetingId attendeeId:(NSString * _Nonnull)attendeeId OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK19MeetingHistoryEvent")
@interface MeetingHistoryEvent : NSObject
@property (nonatomic, readonly) enum MeetingHistoryEventName meetingHistoryEventName;
@property (nonatomic, readonly) int64_t timestampMs;
- (nonnull instancetype)initWithMeetingHistoryEventName:(enum MeetingHistoryEventName)meetingHistoryEventName timestampMs:(int64_t)timestampMs OBJC_DESIGNATED_INITIALIZER;
@property (nonatomic, readonly, copy) NSString * _Nonnull description;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// <code>MeetingHistoryEventName</code> is a meeting history state which are important events to note in the history.
/// Thus, this also includes events in <code>EventName</code>
typedef SWIFT_ENUM(NSInteger, MeetingHistoryEventName, open) {
/// The microphone was selected.
  MeetingHistoryEventNameAudioInputSelected = 0,
/// The camera was selected.
  MeetingHistoryEventNameVideoInputSelected = 1,
/// The camera selection failed.
  MeetingHistoryEventNameVideoInputFailed = 2,
/// The meeting failed to start.
  MeetingHistoryEventNameMeetingStartFailed = 3,
/// The meeting will start.
  MeetingHistoryEventNameMeetingStartRequested = 4,
/// The meeting started.
  MeetingHistoryEventNameMeetingStartSucceeded = 5,
/// The meeting ended.
  MeetingHistoryEventNameMeetingEnded = 6,
/// The meeting failed.
  MeetingHistoryEventNameMeetingFailed = 7,
/// The meeting reconnected.
  MeetingHistoryEventNameMeetingReconnected = 8,
/// unknown
  MeetingHistoryEventNameUnknown = 9,
};


@class MeetingSessionURLs;

/// <code>MeetingSessionConfiguration</code> contains the information necessary to start a session.
/// Constructs a MeetingSessionConfiguration with a chime:<code>CreateMeetingResponse</code> and
/// chime:<code>CreateAttendeeResponse</code> response and optional custom <code>URLRewriter</code> that will
/// rewrite urls given to new urls.
SWIFT_CLASS("_TtC14AmazonChimeSDK27MeetingSessionConfiguration")
@interface MeetingSessionConfiguration : NSObject
/// The id of the meeting the session is joining.
@property (nonatomic, readonly, copy) NSString * _Nonnull meetingId;
/// The external id of the meeting the session is joining. See https://docs.aws.amazon.com/chime/latest/APIReference/API_CreateMeeting.html#API_CreateMeeting_RequestSyntax for more details
@property (nonatomic, readonly, copy) NSString * _Nullable externalMeetingId;
/// The credentials used to authenticate the session.
@property (nonatomic, readonly, strong) MeetingSessionCredentials * _Nonnull credentials;
/// The URLs the session uses to reach the meeting service.
@property (nonatomic, readonly, strong) MeetingSessionURLs * _Nonnull urls;
@property (nonatomic, readonly, copy) NSString * _Nonnull (^ _Nonnull urlRewriter)(NSString * _Nonnull);
/// The id of the primary meeting that this session is joining a replica to
@property (nonatomic, readonly, copy) NSString * _Nullable primaryMeetingId;
- (nonnull instancetype)initWithCreateMeetingResponse:(CreateMeetingResponse * _Nonnull)createMeetingResponse createAttendeeResponse:(CreateAttendeeResponse * _Nonnull)createAttendeeResponse;
- (nonnull instancetype)initWithMeetingId:(NSString * _Nonnull)meetingId credentials:(MeetingSessionCredentials * _Nonnull)credentials urls:(MeetingSessionURLs * _Nonnull)urls urlRewriter:(NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter;
- (nonnull instancetype)initWithMeetingId:(NSString * _Nonnull)meetingId externalMeetingId:(NSString * _Nullable)externalMeetingId credentials:(MeetingSessionCredentials * _Nonnull)credentials urls:(MeetingSessionURLs * _Nonnull)urls urlRewriter:(NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter;
- (nonnull instancetype)initWithMeetingId:(NSString * _Nonnull)meetingId externalMeetingId:(NSString * _Nullable)externalMeetingId credentials:(MeetingSessionCredentials * _Nonnull)credentials urls:(MeetingSessionURLs * _Nonnull)urls urlRewriter:(NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter primaryMeetingId:(NSString * _Nullable)primaryMeetingId OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)initWithCreateMeetingResponse:(CreateMeetingResponse * _Nonnull)createMeetingResponse createAttendeeResponse:(CreateAttendeeResponse * _Nonnull)createAttendeeResponse urlRewriter:(NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>MeetingSessionCredentials</code> includes the credentials used to authenticate.
/// the attendee on the meeting
SWIFT_CLASS("_TtC14AmazonChimeSDK25MeetingSessionCredentials")
@interface MeetingSessionCredentials : NSObject
/// The attendee id for these credentials.
@property (nonatomic, readonly, copy) NSString * _Nonnull attendeeId;
/// The external user Id associated with the attendee.
@property (nonatomic, readonly, copy) NSString * _Nonnull externalUserId;
/// The token that the session will be authenticated with.
@property (nonatomic, readonly, copy) NSString * _Nonnull joinToken;
- (nonnull instancetype)initWithAttendeeId:(NSString * _Nonnull)attendeeId externalUserId:(NSString * _Nonnull)externalUserId joinToken:(NSString * _Nonnull)joinToken OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

enum MeetingSessionStatusCode : uint32_t;

/// <code>MeetingSessionStatus</code> indicates a status received regarding the session.
SWIFT_CLASS("_TtC14AmazonChimeSDK20MeetingSessionStatus")
@interface MeetingSessionStatus : NSObject
@property (nonatomic, readonly) enum MeetingSessionStatusCode statusCode;
- (nonnull instancetype)initWithStatusCode:(enum MeetingSessionStatusCode)statusCode OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

typedef SWIFT_ENUM(uint32_t, MeetingSessionStatusCode, open) {
/// Everything is OK so far.
  MeetingSessionStatusCodeOk = 0,
/// The audio leg failed.
  MeetingSessionStatusCodeAudioDisconnected = 9,
/// Due to connection health a reconnect has been triggered.
  MeetingSessionStatusCodeConnectionHealthReconnect = 10,
/// Network is not good enough for VoIP.
  MeetingSessionStatusCodeNetworkBecomePoor = 59,
/// Server hung up.
  MeetingSessionStatusCodeAudioServerHungup = 60,
/// The attendee joined from another device.
  MeetingSessionStatusCodeAudioJoinedFromAnotherDevice = 61,
/// There was an internal server error with the audio leg.
  MeetingSessionStatusCodeAudioInternalServerError = 62,
/// Authentication was rejected. The client is not allowed on this call.
  MeetingSessionStatusCodeAudioAuthenticationRejected = 63,
/// The client can not join because the call is at capacity.
  MeetingSessionStatusCodeAudioCallAtCapacity = 64,
/// Could not connect the audio leg due to the service being unavailable.
  MeetingSessionStatusCodeAudioServiceUnavailable = 65,
/// The attendee should explicitly switch itself from joined with audio to checked-in.
  MeetingSessionStatusCodeAudioDisconnectAudio = 69,
/// The call was ended.
  MeetingSessionStatusCodeAudioCallEnded = 75,
/// video service is unavailable.
  MeetingSessionStatusCodeVideoServiceUnavailable = 12,
/// If State cannot be parsed, then use this state.
  MeetingSessionStatusCodeUnknown = 78,
/// When maximum concurrent video channel reached
  MeetingSessionStatusCodeVideoAtCapacityViewOnly = 206,
/// Designated input device is not responding and timed out.
  MeetingSessionStatusCodeAudioInputDeviceNotResponding = 82,
/// Designated output device is not responding and timed out.
  MeetingSessionStatusCodeAudioOutputDeviceNotResponding = 83,
};


/// <code>MeetingSessionURLs</code> contains the URLs that will be used to reach the meeting service.
SWIFT_CLASS("_TtC14AmazonChimeSDK18MeetingSessionURLs")
@interface MeetingSessionURLs : NSObject
/// The audio fallback URL of the session
@property (nonatomic, readonly, copy) NSString * _Nonnull audioFallbackUrl;
/// The audio host URL of the session
@property (nonatomic, readonly, copy) NSString * _Nonnull audioHostUrl;
/// The TURN control URL of the session
@property (nonatomic, readonly, copy) NSString * _Nonnull turnControlUrl;
/// The signaling URL of the session
@property (nonatomic, readonly, copy) NSString * _Nonnull signalingUrl;
/// The event ingestion URL of the session
@property (nonatomic, readonly, copy) NSString * _Nullable ingestionUrl;
- (nonnull instancetype)initWithAudioFallbackUrl:(NSString * _Nonnull)audioFallbackUrl audioHostUrl:(NSString * _Nonnull)audioHostUrl turnControlUrl:(NSString * _Nonnull)turnControlUrl signalingUrl:(NSString * _Nonnull)signalingUrl urlRewriter:(SWIFT_NOESCAPE NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter;
- (nonnull instancetype)initWithAudioFallbackUrl:(NSString * _Nonnull)audioFallbackUrl audioHostUrl:(NSString * _Nonnull)audioHostUrl turnControlUrl:(NSString * _Nonnull)turnControlUrl signalingUrl:(NSString * _Nonnull)signalingUrl urlRewriter:(SWIFT_NOESCAPE NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))urlRewriter ingestionUrl:(NSString * _Nullable)ingestionUrl OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end



/// <code>MetricsObserver</code> handles events related to audio/video metrics.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK15MetricsObserver_")
@protocol MetricsObserver
/// Called when metrics are collected and ready
/// \param metrics A dictionary of ObservableMetric case to value
///
- (void)metricsDidReceiveWithMetrics:(NSDictionary * _Nonnull)metrics;
@end

typedef SWIFT_ENUM(NSInteger, ModalityType, open) {
  ModalityTypeContent = 0,
};
static NSString * _Nonnull const ModalityTypeDomain = @"AmazonChimeSDK.ModalityType";


@interface NSDictionary<KeyType, ObjectType> (SWIFT_EXTENSION(AmazonChimeSDK))
- (NSString * _Nonnull)toJsonString SWIFT_WARN_UNUSED_RESULT;
@end


@interface NSLock (SWIFT_EXTENSION(AmazonChimeSDK)) <AudioLock>
@end

/// <code>ObservableMetric</code> types represents filtered metrics that are intended to propagate to the
/// top level observers. All metrics are measured over the past second.
/// Send video metrics are only reported when sending.
/// Receive video metrics are only reported when receiving.
typedef SWIFT_ENUM(NSInteger, ObservableMetric, open) {
/// Percentage of audio packets lost from server to client
  ObservableMetricAudioReceivePacketLossPercent = 0,
/// Percentage of audio packets lost from client to server
  ObservableMetricAudioSendPacketLossPercent = 1,
/// Estimated uplink bandwidth from perspective of video client
  ObservableMetricVideoAvailableSendBandwidth = 2,
/// Estimated downlink bandwidth from perspective of video client
  ObservableMetricVideoAvailableReceiveBandwidth = 3,
/// Sum of total bitrate across all send streams
  ObservableMetricVideoSendBitrate = 4,
/// Percentage of video packets lost from client to server across all send streams
  ObservableMetricVideoSendPacketLossPercent = 5,
/// Average send FPS across all send streams
  ObservableMetricVideoSendFps = 6,
/// Round trip time of packets sent from client to server
  ObservableMetricVideoSendRttMs = 7,
/// Sum of total bitrate across all receive streams
  ObservableMetricVideoReceiveBitrate = 8,
/// Percentage of video packets lost from server to client across all receive streams
  ObservableMetricVideoReceivePacketLossPercent = 9,
/// Sum of total bitrate across all send streams
  ObservableMetricContentShareVideoSendBitrate = 10,
/// Percentage of video packets lost from client to server across all send streams
  ObservableMetricContentShareVideoSendPacketLossPercent = 11,
/// Average send FPS across all send streams
  ObservableMetricContentShareVideoSendFps = 12,
/// Round trip time of packets sent from client to server
  ObservableMetricContentShareVideoSendRttMs = 13,
};

typedef SWIFT_ENUM(NSInteger, PermissionError, open) {
  PermissionErrorAudioPermissionError = 0,
  PermissionErrorVideoPermissionError = 1,
};
static NSString * _Nonnull const PermissionErrorDomain = @"AmazonChimeSDK.PermissionError";


/// <code>PrimaryMeetingPromotionObserver</code> handles events related to Primary meeting promotion.
/// See <code>AudioVideoControllerFacade.promoteToPrimaryMeeting</code> for more information.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK31PrimaryMeetingPromotionObserver_")
@protocol PrimaryMeetingPromotionObserver
/// Called when the <code>AudioVideoControllerFacade.promoteToPrimaryMeeting</code> completes.
/// <code>MeetingSessionStatus</code>  that will contain a <code>MeetingSessionStatusCode</code> of the following:
/// <ul>
///   <li>
///     <code>MeetingSessionStatusCode.ok</code>: The promotion was successful (i.e. session token was valid,
///     there was room in the Primary meeting, etc.), audio will begin flowing
///     and the attendee can begin to send data messages, and content/video if the call is not already at limit.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioAuthenticationRejected</code>: Credentials provided
///     were invalid when connection attempted to Primary meeting. There may be an issue
///     with your mechanism which allocates the Primary meeting attendee for the Replica
///     meeting proxied promotion.  This also may indicate that this API was called in a
///     non-Replica meeting.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioCallAtCapacity</code>: Credentials provided were correct
///     but there was no room in the Primary meeting.  Promotions to Primary meeting attendee take up a slot, just like
///     regular Primary meeting attendee connections and are limited by the same mechanisms.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioServiceUnavailable</code>: Media has not been connected yet so promotion is not yet possible.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioInternalServerError</code>: Other failure, possibly due to disconnect
///     or timeout. These failures are likely retryable.
///   </li>
/// </ul>
/// Note: this callback will be called on main thread.
/// \param status See notes above
///
- (void)didPromoteToPrimaryMeetingWithStatus:(MeetingSessionStatus * _Nonnull)status;
/// This observer callback will only be called for attendees in Replica meetings that have
/// been promoted to the Primary meeting via <code>AudioVideoFacade.promoteToPrimaryMeeting</code>.
/// Indicates that the client is no longer authenticated to the Primary meeting
/// and can no longer share media. <code>status</code> will contain a <code>MeetingSessionStatusCode</code> of the following:
/// <ul>
///   <li>
///     <code>MeetingSessionStatusCode.ok</code>: <code>AudioVideoFacade.demoteFromPrimaryMeeting</code> was used to remove the attendee.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioAuthenticationRejected</code>: <code>chime::DeleteAttendee</code> was called on the Primary
///     meeting attendee used in <code>AudioVideoFacade.promoteToPrimaryMeeting</code>.
///   </li>
///   <li>
///     <code>MeetingSessionStatusCode.audioInternalServerError</code>: Other failure, possibly due to disconnect
///     or timeout. These failures are likely retryable. Any disconnection will trigger an automatic
///     demotion to avoid unexpected or unwanted promotion state on reconnection.
///   </li>
/// </ul>
/// Note: this callback will be called on main thread.
/// \param status See notes above
///
- (void)didDemoteFromPrimaryMeetingWithStatus:(MeetingSessionStatus * _Nonnull)status;
@end




/// A video source available in the current meeting. RemoteVideoSource need to be consistent between <code>remoteVideoSourcesDidBecomeAvailable</code>
/// and <code>updateVideoSourceSubscriptions</code> as they are used as keys in maps that may be updated.
/// I.e. when setting up a map for <code>updateVideoSourceSubscriptions</code> do not construct RemoteVideoSource yourselves
/// or the configuration may or may not be updated.
SWIFT_CLASS("_TtC14AmazonChimeSDK17RemoteVideoSource")
@interface RemoteVideoSource : NSObject
/// <ul>
///   <li>
///     Parameters:
///     -attendeeId: The attendee ID this video tile belongs to. Note that screen share video will have a suffix of #content
///   </li>
/// </ul>
@property (nonatomic, copy) NSString * _Nonnull attendeeId;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end

typedef SWIFT_ENUM(NSInteger, ResourceError, open) {
  ResourceErrorNotFound = 0,
};
static NSString * _Nonnull const ResourceErrorDomain = @"AmazonChimeSDK.ResourceError";


/// <code>SDKEvent</code> defines event that composes of name of event and attribute to describe the event
SWIFT_CLASS("_TtC14AmazonChimeSDK8SDKEvent")
@interface SDKEvent : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull name;
@property (nonatomic, readonly, copy) NSDictionary * _Nonnull eventAttributes;
- (nonnull instancetype)initWithMeetingHistoryEventName:(enum MeetingHistoryEventName)meetingHistoryEventName eventAttributes:(NSDictionary * _Nonnull)eventAttributes OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)initWithEventName:(enum EventName)eventName eventAttributes:(NSDictionary * _Nonnull)eventAttributes OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


typedef SWIFT_ENUM(NSInteger, SendDataMessageError, open) {
  SendDataMessageErrorInvalidDataLength = 0,
  SendDataMessageErrorInvalidTopic = 1,
  SendDataMessageErrorNegativeLifetimeParameter = 2,
  SendDataMessageErrorInvalidData = 3,
};
static NSString * _Nonnull const SendDataMessageErrorDomain = @"AmazonChimeSDK.SendDataMessageError";

/// <code>SignalStrength</code> describes the signal strength of an attendee for audio.
typedef SWIFT_ENUM(NSInteger, SignalStrength, open) {
/// The attendee has no signal
  SignalStrengthNone = 0,
/// The attendee has low signal
  SignalStrengthLow = 1,
/// The attendee has high signal
  SignalStrengthHigh = 2,
};


SWIFT_CLASS("_TtC14AmazonChimeSDK12SignalUpdate")
@interface SignalUpdate : NSObject
@property (nonatomic, readonly, strong) AttendeeInfo * _Nonnull attendeeInfo;
@property (nonatomic, readonly) enum SignalStrength signalStrength;
- (nonnull instancetype)initWithAttendeeInfo:(AttendeeInfo * _Nonnull)attendeeInfo signalStrength:(enum SignalStrength)signalStrength OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


SWIFT_CLASS("_TtC14AmazonChimeSDK18TURNRequestService")
@interface TURNRequestService : NSObject
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end


/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK15TranscriptEvent_")
@protocol TranscriptEvent
@end

@class TranscriptResult;

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK10Transcript")
@interface Transcript : NSObject <TranscriptEvent>
@property (nonatomic, readonly, copy) NSArray<TranscriptResult *> * _Nonnull results;
- (nonnull instancetype)initWithResults:(NSArray<TranscriptResult *> * _Nonnull)results OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

@class TranscriptItem;
@class TranscriptEntity;

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK21TranscriptAlternative")
@interface TranscriptAlternative : NSObject
@property (nonatomic, readonly, copy) NSArray<TranscriptItem *> * _Nonnull items;
@property (nonatomic, readonly, copy) NSArray<TranscriptEntity *> * _Nullable entities;
@property (nonatomic, readonly, copy) NSString * _Nonnull transcript;
- (nonnull instancetype)initWithItems:(NSArray<TranscriptItem *> * _Nonnull)items transcript:(NSString * _Nonnull)transcript entities:(NSArray<TranscriptEntity *> * _Nullable)entities OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK16TranscriptEntity")
@interface TranscriptEntity : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull type;
@property (nonatomic, readonly, copy) NSString * _Nonnull content;
@property (nonatomic, readonly, copy) NSString * _Nonnull category;
@property (nonatomic, readonly) int64_t startTimeMs;
@property (nonatomic, readonly) int64_t endTimeMs;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end



/// <code>TranscriptEventObserver</code> provides a callback to handle transcript event
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK23TranscriptEventObserver_")
@protocol TranscriptEventObserver
/// Gets triggered when a transcript event is received
/// Note: this callback will be called on main thread.
/// \param transcriptEvent The transcript event received
///
- (void)transcriptEventDidReceiveWithTranscriptEvent:(id <TranscriptEvent> _Nonnull)transcriptEvent;
@end

enum TranscriptItemType : NSInteger;

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK14TranscriptItem")
@interface TranscriptItem : NSObject
@property (nonatomic, readonly) enum TranscriptItemType type;
@property (nonatomic, readonly) int64_t startTimeMs;
@property (nonatomic, readonly) int64_t endTimeMs;
@property (nonatomic, readonly, strong) AttendeeInfo * _Nonnull attendee;
@property (nonatomic, readonly, copy) NSString * _Nonnull content;
@property (nonatomic, readonly) BOOL vocabularyFilterMatch;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
typedef SWIFT_ENUM(NSInteger, TranscriptItemType, open) {
  TranscriptItemTypeUnknown = 0,
  TranscriptItemTypePronunciation = 1,
  TranscriptItemTypePunctuation = 2,
};


/// See <a href="https://docs.aws.amazon.com/transcribe/latest/dg/lang-id.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK27TranscriptLanguageWithScore")
@interface TranscriptLanguageWithScore : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull languageCode;
@property (nonatomic, readonly) double score;
- (nonnull instancetype)initWithLanguageCode:(NSString * _Nonnull)languageCode score:(double)score OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK16TranscriptResult")
@interface TranscriptResult : NSObject
@property (nonatomic, readonly, copy) NSString * _Nonnull resultId;
@property (nonatomic, readonly, copy) NSString * _Nullable channelId;
@property (nonatomic, readonly) BOOL isPartial;
@property (nonatomic, readonly) int64_t startTimeMs;
@property (nonatomic, readonly) int64_t endTimeMs;
@property (nonatomic, readonly, copy) NSArray<TranscriptAlternative *> * _Nonnull alternatives;
@property (nonatomic, readonly, copy) NSString * _Nullable languageCode;
@property (nonatomic, readonly, copy) NSArray<TranscriptLanguageWithScore *> * _Nullable languageIdentification;
- (nonnull instancetype)initWithResultId:(NSString * _Nonnull)resultId channelId:(NSString * _Nullable)channelId isPartial:(BOOL)isPartial startTimeMs:(int64_t)startTimeMs endTimeMs:(int64_t)endTimeMs alternatives:(NSArray<TranscriptAlternative *> * _Nonnull)alternatives languageCode:(NSString * _Nullable)languageCode languageIdentification:(NSArray<TranscriptLanguageWithScore *> * _Nullable)languageIdentification OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

enum TranscriptionStatusType : NSInteger;

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
SWIFT_CLASS("_TtC14AmazonChimeSDK19TranscriptionStatus")
@interface TranscriptionStatus : NSObject <TranscriptEvent>
@property (nonatomic, readonly) enum TranscriptionStatusType type;
@property (nonatomic, readonly) int64_t eventTimeMs;
@property (nonatomic, readonly, copy) NSString * _Nonnull transcriptionRegion;
@property (nonatomic, readonly, copy) NSString * _Nonnull transcriptionConfiguration;
@property (nonatomic, readonly, copy) NSString * _Nullable message;
- (nonnull instancetype)initWithType:(enum TranscriptionStatusType)type eventTimeMs:(int64_t)eventTimeMs transcriptionRegion:(NSString * _Nonnull)transcriptionRegion transcriptionConfiguration:(NSString * _Nonnull)transcriptionConfiguration message:(NSString * _Nullable)message OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// See <a href="https://docs.aws.amazon.com/chime/latest/dg/process-msgs.html">Using Amazon Chime SDK live transcription developer guide</a> for details about transcription message types and data guidelines
typedef SWIFT_ENUM(NSInteger, TranscriptionStatusType, open) {
  TranscriptionStatusTypeUnknown = 0,
  TranscriptionStatusTypeStarted = 1,
  TranscriptionStatusTypeInterrupted = 2,
  TranscriptionStatusTypeResumed = 3,
  TranscriptionStatusTypeStopped = 4,
  TranscriptionStatusTypeFailed = 5,
};


/// <code>URLRewriterUtils</code> is class that defines default Url rewrite behavior
SWIFT_CLASS("_TtC14AmazonChimeSDK16URLRewriterUtils")
@interface URLRewriterUtils : NSObject
/// The default implementation returns the original URL unchanged.
SWIFT_CLASS_PROPERTY(@property (nonatomic, class, readonly, copy) NSString * _Nonnull (^ _Nonnull defaultUrlRewriter)(NSString * _Nonnull);)
+ (NSString * _Nonnull (^ _Nonnull)(NSString * _Nonnull))defaultUrlRewriter SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end



SWIFT_CLASS("_TtC14AmazonChimeSDK10Versioning")
@interface Versioning : NSObject
/// Returns the current version of Amazon Chime SDK in the format of string.
/// If there is an error with the version, empty string will be returned.
+ (NSString * _Nonnull)sdkVersion SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end

@class AVCaptureDeviceFormat;

/// <code>VideoCaptureFormat</code>describes a given capture format that may be possible to apply to a <code>VideoCaptureSource</code>.
/// Note that <code>VideoCaptureSource</code> implementations may ignore or adjust unsupported values.
SWIFT_CLASS("_TtC14AmazonChimeSDK18VideoCaptureFormat")
@interface VideoCaptureFormat : NSObject
/// Capture width in pixels.
@property (nonatomic, readonly) NSInteger width;
/// Capture height in pixels.
@property (nonatomic, readonly) NSInteger height;
/// Max frame rate. When used as input this implies the desired frame rate as well.
@property (nonatomic, readonly) NSInteger maxFrameRate;
- (nonnull instancetype)initWithWidth:(NSInteger)width height:(NSInteger)height maxFrameRate:(NSInteger)maxFrameRate OBJC_DESIGNATED_INITIALIZER;
- (BOOL)isEqual:(id _Nullable)object SWIFT_WARN_UNUSED_RESULT;
/// Helper function to convert <code>AVCaptureDevice.Format</code> to <code>VideoCaptureFormat</code>
/// \param format format from the <code>AVCaptureDevice</code>
///
+ (VideoCaptureFormat * _Nonnull)fromAVCaptureDeviceFormatWithFormat:(AVCaptureDeviceFormat * _Nonnull)format SWIFT_WARN_UNUSED_RESULT;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


@class VideoConfiguration;
@protocol VideoSourceInternal;

SWIFT_PROTOCOL("_TtP14AmazonChimeSDK19VideoClientProtocol_")
@protocol VideoClientProtocol
@property (nonatomic, strong) id <VideoClientDelegate> _Null_unspecified delegate;
+ (void)globalInitialize;
- (void)start:(NSString * _Null_unspecified)callId token:(NSString * _Null_unspecified)token sending:(BOOL)sending config:(VideoConfiguration * _Null_unspecified)config appInfo:(app_detailed_info_t)appInfo signalingUrl:(NSString * _Null_unspecified)signalingUrl;
- (void)start:(NSString * _Null_unspecified)callId token:(NSString * _Null_unspecified)token sending:(BOOL)sending config:(VideoConfiguration * _Null_unspecified)config appInfo:(app_detailed_info_t)appInfo;
- (void)stop;
- (void)setSending:(BOOL)sending;
- (void)setReceiving:(BOOL)receiving;
- (void)setExternalVideoSource:(id <VideoSourceInternal> _Null_unspecified)source;
- (video_client_service_type_t)getServiceType SWIFT_WARN_UNUSED_RESULT;
- (void)setRemotePause:(uint32_t)video_id pause:(BOOL)pause;
- (void)videoLogCallBack:(video_client_loglevel_t)logLevel msg:(NSString * _Null_unspecified)msg;
- (void)sendDataMessage:(NSString * _Null_unspecified)topic data:(int8_t const * _Null_unspecified)data dataLen:(uint32_t)dataLen lifetimeMs:(int32_t)lifetimeMs;
- (void)updateVideoSourceSubscriptions:(NSDictionary * _Null_unspecified)addedOrUpdated withRemoved:(NSArray * _Null_unspecified)withRemoved;
- (void)promotePrimaryMeeting:(NSString * _Null_unspecified)attendeeId externalUserId:(NSString * _Null_unspecified)externalUserId joinToken:(NSString * _Null_unspecified)joinToken;
- (void)demoteFromPrimaryMeeting;
- (void)setSimulcast:(BOOL)simulcast;
- (void)setMaxBitRateKbps:(uint32_t)maxBitRate;
@end


@interface VideoClient (SWIFT_EXTENSION(AmazonChimeSDK)) <VideoClientProtocol>
@end


SWIFT_PROTOCOL("_TtP14AmazonChimeSDK21VideoClientController_")
@protocol VideoClientController
- (void)start;
- (void)stopAndDestroy;
- (BOOL)startLocalVideoAndReturnError:(NSError * _Nullable * _Nullable)error;
- (BOOL)startLocalVideoWithConfig:(LocalVideoConfiguration * _Nonnull)config error:(NSError * _Nullable * _Nullable)error;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source;
- (void)startLocalVideoWithSource:(id <VideoSource> _Nonnull)source config:(LocalVideoConfiguration * _Nonnull)config;
- (void)stopLocalVideo;
- (void)startRemoteVideo;
- (void)stopRemoteVideo;
- (void)switchCamera;
- (MediaDevice * _Nullable)getCurrentDevice SWIFT_WARN_UNUSED_RESULT;
- (MeetingSessionConfiguration * _Nonnull)getConfiguration SWIFT_WARN_UNUSED_RESULT;
- (void)subscribeToVideoClientStateChangeWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)unsubscribeFromVideoClientStateChangeWithObserver:(id <AudioVideoObserver> _Nonnull)observer;
- (void)subscribeToVideoTileControllerObserversWithObserver:(id <VideoTileController> _Nonnull)observer;
- (void)unsubscribeFromVideoTileControllerObserversWithObserver:(id <VideoTileController> _Nonnull)observer;
- (void)pauseResumeRemoteVideo:(uint32_t)videoId pause:(BOOL)pause;
- (void)subscribeToReceiveDataMessageWithTopic:(NSString * _Nonnull)topic observer:(id <DataMessageObserver> _Nonnull)observer;
- (void)unsubscribeFromReceiveDataMessageFromTopicWithTopic:(NSString * _Nonnull)topic;
- (BOOL)sendDataMessageWithTopic:(NSString * _Nonnull)topic data:(id _Nonnull)data lifetimeMs:(int32_t)lifetimeMs error:(NSError * _Nullable * _Nullable)error;
- (void)updateVideoSourceSubscriptionsWithAddedOrUpdated:(NSDictionary<RemoteVideoSource *, VideoSubscriptionConfiguration *> * _Nonnull)addedOrUpdated removed:(NSArray<RemoteVideoSource *> * _Nonnull)removed;
- (void)promoteToPrimaryMeetingWithCredentials:(MeetingSessionCredentials * _Nonnull)credentials observer:(id <PrimaryMeetingPromotionObserver> _Nonnull)observer;
- (void)demoteFromPrimaryMeeting;
@end


/// <code>VideoContentHint</code> describes the content type of a video source so that downstream encoders, etc. can properly
/// decide on what parameters will work best. These options mirror https://www.w3.org/TR/mst-content-hint/ .
typedef SWIFT_ENUM(NSInteger, VideoContentHint, open) {
/// No hint has been provided.
  VideoContentHintNone = 0,
/// The track should be treated as if it contains video where motion is important.
/// This is normally webcam video, movies or video games.
  VideoContentHintMotion = 1,
/// The track should be treated as if video details are extra important.
/// This is generally applicable to presentations or web pages with text content, painting or line art.
  VideoContentHintDetail = 2,
/// The track should be treated as if video details are extra important, and that
/// significant sharp edges and areas of consistent color can occur frequently.
/// This is generally applicable to presentations or web pages with text content.
  VideoContentHintText = 3,
};

enum VideoRotation : NSInteger;
@protocol VideoFrameBuffer;

/// <code>VideoFrame</code> is a class which contains a <code>VideoFrameBuffer</code> and metadata necessary for transmission.
/// Typically produced via a <code>VideoSource</code> and consumed via a <code>VideoSink</code>
SWIFT_CLASS("_TtC14AmazonChimeSDK10VideoFrame")
@interface VideoFrame : NSObject
/// Width of the video frame in pixels.
@property (nonatomic, readonly) NSInteger width;
/// Height of the video frame in pixels.
@property (nonatomic, readonly) NSInteger height;
/// Timestamp in nanoseconds at which the video frame was captured from some system monotonic clock.
/// Will be aligned and converted to NTP (Network Time Protocol) within AmazonChimeSDKMedia framework,
/// which will then be converted to a system monotonic clock on remote end.
/// May be different on frames emanated from AmazonChimeSDKMedia framework.
@property (nonatomic, readonly) int64_t timestampNs;
/// Rotation of the video frame buffer in degrees clockwise from intended viewing horizon.
/// e.g. If you were recording camera capture upside down relative to
/// the orientation of the sensor, this value would be <code>VideoRotation.rotation180</code>.
@property (nonatomic, readonly) enum VideoRotation rotation;
/// Object containing actual video frame data in some form.
@property (nonatomic, readonly, strong) id <VideoFrameBuffer> _Nonnull buffer;
- (nonnull instancetype)initWithTimestampNs:(int64_t)timestampNs rotation:(enum VideoRotation)rotation buffer:(id <VideoFrameBuffer> _Nonnull)buffer OBJC_DESIGNATED_INITIALIZER;
- (nullable instancetype)initWithSampleBuffer:(CMSampleBufferRef _Nonnull)sampleBuffer OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>VideoFrameBuffer</code> is a buffer which contains a single video buffer’s raw data.
/// Typically owned by a <code>VideoFrame</code> which includes additional metadata.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK16VideoFrameBuffer_")
@protocol VideoFrameBuffer
/// Width of the video frame in pixels.
- (NSInteger)width SWIFT_WARN_UNUSED_RESULT;
/// Height of the video frame in pixels.
- (NSInteger)height SWIFT_WARN_UNUSED_RESULT;
@end


/// <code>VideoFramePixelBuffer</code> is a buffer which contains a single video frame in the form of <code>CVPixelBuffer</code>.
SWIFT_CLASS("_TtC14AmazonChimeSDK21VideoFramePixelBuffer")
@interface VideoFramePixelBuffer : NSObject <VideoFrameBuffer>
- (NSInteger)width SWIFT_WARN_UNUSED_RESULT;
- (NSInteger)height SWIFT_WARN_UNUSED_RESULT;
@property (nonatomic, readonly) CVPixelBufferRef _Nonnull pixelBuffer;
- (nonnull instancetype)initWithPixelBuffer:(CVPixelBufferRef _Nonnull)pixelBuffer OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end


/// <code>VideoFrameResender</code> contains logic to resend video frames as needed to maintain a minimum frame rate
/// This can be useful with sources which may pause the generation of frames (like in-app ReplayKit screen sharing)
/// so that internally encoders don’t get in a poor state, and new receivers can immediately receive frames
SWIFT_CLASS("_TtC14AmazonChimeSDK18VideoFrameResender")
@interface VideoFrameResender : NSObject
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// <code>VideoPauseState</code> describes the pause status of a video tile.
typedef SWIFT_ENUM(NSInteger, VideoPauseState, open) {
/// The video tile is not paused
  VideoPauseStateUnpaused = 0,
/// The video tile has been paused by the user, and will only be unpaused if the user requests it to resume.
  VideoPauseStatePausedByUserRequest = 1,
/// The video tile has been paused to save on local downlink bandwidth. When the connection improves,
/// it will be automatically unpaused by the client. User requested pauses will shadow this pause,
/// but if the connection has not recovered on resume the tile will still be paused with this state.
  VideoPauseStatePausedForPoorConnection = 2,
};

/// Enum defining video priority for remote video sources. The ‘higher’ the number the ‘higher’ the priority for the source when adjusting video quality
/// to adapt to variable network conditions, i.e. <code>highest</code> will be chosen before <code>high</code>, <code>medium</code>, etc.
typedef SWIFT_ENUM(NSInteger, VideoPriority, open) {
  VideoPriorityLowest = 0,
  VideoPriorityLow = 10,
  VideoPriorityMedium = 20,
  VideoPriorityHigh = 30,
  VideoPriorityHighest = 40,
};



/// Customizable video resolution parameters for a remote video source.
SWIFT_CLASS("_TtC14AmazonChimeSDK15VideoResolution")
@interface VideoResolution : NSObject
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end

/// <code>VideoRotation</code> describes the rotation of the video frame buffer in degrees clockwise
/// from intended viewing horizon.
/// e.g. If you were recording camera capture upside down relative to
/// the orientation of the sensor, this value would be <code>VideoRotation.rotation180</code>.
typedef SWIFT_ENUM(NSInteger, VideoRotation, open) {
/// Not rotated.
  VideoRotationRotation0 = 0,
/// Rotated 90 degrees clockwise.
  VideoRotationRotation90 = 90,
/// Rotated 180 degrees clockwise.
  VideoRotationRotation180 = 180,
/// Rotated 270 degrees clockwise.
  VideoRotationRotation270 = 270,
};




/// Configuration for a specific video source.
/// The values are intentionally mutable so that a map of all current configurations can be kept and updated as needed.
/// <code>VideoSubscriptionConfiguration</code> is used to contain the priority and resolution of
/// remote video sources and content share to be received
SWIFT_CLASS("_TtC14AmazonChimeSDK30VideoSubscriptionConfiguration")
@interface VideoSubscriptionConfiguration : NSObject
/// <ul>
///   <li>
///     priority: Relative priority for the subscription.
///   </li>
///   <li>
///     targetResolution: A target resolution for the subscription. The actual receive resolution may vary.
///   </li>
/// </ul>
@property (nonatomic) enum VideoPriority priority;
@property (nonatomic, strong) VideoResolution * _Nonnull targetResolution;
- (nonnull instancetype)init OBJC_DESIGNATED_INITIALIZER;
@end





/// <code>VideoTileObserver</code> handles events related to <code>VideoTile</code>.
SWIFT_PROTOCOL("_TtP14AmazonChimeSDK17VideoTileObserver_")
@protocol VideoTileObserver
/// Called whenever a new attendee starts sharing the video
/// Note: this callback will be called on main thread.
/// \param tileState video tile state associated with this attendee
///
- (void)videoTileDidAddWithTileState:(VideoTileState * _Nonnull)tileState;
/// Called whenever any attendee stops sharing the video
/// Note: this callback will be called on main thread.
/// \param tileState video tile state associated with this attendee
///
- (void)videoTileDidRemoveWithTileState:(VideoTileState * _Nonnull)tileState;
/// Called whenever an attendee tile pauseState changes from .unpaused
/// Note: this callback will be called on main thread.
/// \param tileState video tile state associated with this attendee
///
- (void)videoTileDidPauseWithTileState:(VideoTileState * _Nonnull)tileState;
/// Called whenever an attendee tile pauseState changes to .unpaused
/// Note: this callback will be called on main thread.
/// \param tileState video tile state associated with this attendee
///
- (void)videoTileDidResumeWithTileState:(VideoTileState * _Nonnull)tileState;
/// Called whenever a video steam size is changed
/// Note: this callback will be called on main thread.
/// \param tileState video tile state whose size was changed
///
- (void)videoTileSizeDidChangeWithTileState:(VideoTileState * _Nonnull)tileState;
@end


/// <code>VideoTileState</code> encapsulates the state of a <code>VideoTile</code>.
SWIFT_CLASS("_TtC14AmazonChimeSDK14VideoTileState")
@interface VideoTileState : NSObject
/// Unique Id associated with this tile
@property (nonatomic, readonly) NSInteger tileId;
/// Id of the user associated with this tile
@property (nonatomic, readonly, copy) NSString * _Nonnull attendeeId;
/// Width of video stream content
@property (nonatomic) NSInteger videoStreamContentWidth;
/// Height of video stream content
@property (nonatomic) NSInteger videoStreamContentHeight;
/// Current pause state of this tile
@property (nonatomic) enum VideoPauseState pauseState;
/// Whether tile is local or remote tile
@property (nonatomic, readonly) BOOL isLocalTile;
/// Whether this is screen share
@property (nonatomic, readonly) BOOL isContent;
- (nonnull instancetype)initWithTileId:(NSInteger)tileId attendeeId:(NSString * _Nonnull)attendeeId videoStreamContentWidth:(NSInteger)videoStreamContentWidth videoStreamContentHeight:(NSInteger)videoStreamContentHeight pauseState:(enum VideoPauseState)pauseState isLocalTile:(BOOL)isLocalTile OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

/// <code>VolumeLevel</code> describes the volume level of an attendee for audio.
typedef SWIFT_ENUM(NSInteger, VolumeLevel, open) {
/// The attendee is muted
  VolumeLevelMuted = -1,
/// The attendee is not speaking
  VolumeLevelNotSpeaking = 0,
/// The attendee is speaking at low volume
  VolumeLevelLow = 1,
/// The attendee is speaking at medium volume
  VolumeLevelMedium = 2,
/// The attendee is speaking at high volume
  VolumeLevelHigh = 3,
};


SWIFT_CLASS("_TtC14AmazonChimeSDK12VolumeUpdate")
@interface VolumeUpdate : NSObject
@property (nonatomic, readonly, strong) AttendeeInfo * _Nonnull attendeeInfo;
@property (nonatomic, readonly) enum VolumeLevel volumeLevel;
- (nonnull instancetype)initWithAttendeeInfo:(AttendeeInfo * _Nonnull)attendeeInfo volumeLevel:(enum VolumeLevel)volumeLevel OBJC_DESIGNATED_INITIALIZER;
- (nonnull instancetype)init SWIFT_UNAVAILABLE;
+ (nonnull instancetype)new SWIFT_UNAVAILABLE_MSG("-init is unavailable");
@end

#endif
#if defined(__cplusplus)
#endif
#if __has_attribute(external_source_symbol)
# pragma clang attribute pop
#endif
#pragma clang diagnostic pop
#endif

#else
#error unsupported Swift architecture
#endif
